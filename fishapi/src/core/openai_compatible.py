#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenAIå…¼å®¹çš„APIæ¥å£
å°†Fish Audio TTSå’ŒLLMåŠŸèƒ½åŒ…è£…æˆOpenAI SDKå¯ç›´æ¥è°ƒç”¨çš„æ ¼å¼
"""

import asyncio
from typing import AsyncGenerator, Optional, Dict, Any, List
from dataclasses import dataclass
import base64
import time
import json

from .vllm_stream import UnifiedLLMClient
from .fish_websocket import FishWebSocketClient


@dataclass
class ChatCompletionChunk:
    """æµå¼èŠå¤©å®Œæˆå“åº”å—"""
    id: str
    object: str = "chat.completion.chunk"
    created: int = None
    model: str = "gpt-3.5-turbo"
    
    def __post_init__(self):
        if self.created is None:
            self.created = int(time.time())


@dataclass
class ChatCompletionResponse:
    """èŠå¤©å®Œæˆå“åº”"""
    id: str
    object: str = "chat.completion"
    created: int = None
    model: str = "gpt-3.5-turbo"
    
    def __post_init__(self):
        if self.created is None:
            self.created = int(time.time())


@dataclass
class AudioResponse:
    """éŸ³é¢‘ç”Ÿæˆå“åº”"""
    data: bytes
    format: str = "mp3"


class OpenAICompatibleClient:
    """OpenAIå…¼å®¹çš„å®¢æˆ·ç«¯"""
    
    def __init__(self):
        """åˆå§‹åŒ–OpenAIå…¼å®¹å®¢æˆ·ç«¯"""
        self.llm_client = UnifiedLLMClient()
        self.tts_client = FishWebSocketClient()
        
    # ==================== Chat Completions API ====================
    
    async def chat_completions_create(self,
                                    messages: List[Dict[str, str]],
                                    model: str = "gpt-3.5-turbo",
                                    stream: bool = False,
                                    temperature: float = 0.7,
                                    max_tokens: Optional[int] = None,
                                    **kwargs) -> AsyncGenerator[Dict[str, Any], None]:
        """
        åˆ›å»ºèŠå¤©å®Œæˆï¼ˆå…¼å®¹OpenAI chat.completions.createæ¥å£ï¼‰
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            model: æ¨¡å‹åç§°ï¼ˆä¿æŒå…¼å®¹æ€§ï¼Œå®é™…ä½¿ç”¨é…ç½®ä¸­çš„æ¨¡å‹ï¼‰
            stream: æ˜¯å¦æµå¼è¿”å›
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§tokenæ•°
            **kwargs: å…¶ä»–å‚æ•°
            
        Yields:
            Dict: å…¼å®¹OpenAIæ ¼å¼çš„å“åº”
        """
        # æå–ç³»ç»Ÿæç¤ºè¯å’Œç”¨æˆ·è¾“å…¥
        system_prompt = None
        user_input = ""
        
        for message in messages:
            if message["role"] == "system":
                system_prompt = message["content"]
            elif message["role"] == "user":
                user_input = message["content"]
        
        if stream:
            # æµå¼å“åº”
            chunk_id = f"chatcmpl-{int(time.time())}"
            
            async for content in self.llm_client.stream_chat(user_input, system_prompt):
                chunk = {
                    "id": chunk_id,
                    "object": "chat.completion.chunk",
                    "created": int(time.time()),
                    "model": model,
                    "choices": [{
                        "index": 0,
                        "delta": {"content": content},
                        "finish_reason": None
                    }]
                }
                yield chunk
            
            # ç»“æŸå—
            end_chunk = {
                "id": chunk_id,
                "object": "chat.completion.chunk",
                "created": int(time.time()),
                "model": model,
                "choices": [{
                    "index": 0,
                    "delta": {},
                    "finish_reason": "stop"
                }]
            }
            yield end_chunk
        else:
            # éæµå¼å“åº”
            full_response = ""
            async for content in self.llm_client.stream_chat(user_input, system_prompt):
                full_response += content
            
            response = {
                "id": f"chatcmpl-{int(time.time())}",
                "object": "chat.completion",
                "created": int(time.time()),
                "model": model,
                "choices": [{
                    "index": 0,
                    "message": {
                        "role": "assistant",
                        "content": full_response
                    },
                    "finish_reason": "stop"
                }],
                "usage": {
                    "prompt_tokens": len(user_input.split()),
                    "completion_tokens": len(full_response.split()),
                    "total_tokens": len(user_input.split()) + len(full_response.split())
                }
            }
            yield response

    # ==================== Audio API ====================
    
    async def audio_speech_create(self,
                                model: str = "tts-1",
                                input: str = "",
                                voice: str = "alloy",
                                response_format: str = "mp3",
                                speed: float = 1.0,
                                **kwargs) -> bytes:
        """
        æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆå…¼å®¹OpenAI audio.speech.createæ¥å£ï¼‰
        
        Args:
            model: TTSæ¨¡å‹åç§°ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
            input: è¾“å…¥æ–‡æœ¬
            voice: éŸ³è‰²åç§°ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
            response_format: å“åº”æ ¼å¼
            speed: è¯­é€Ÿï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            bytes: éŸ³é¢‘æ•°æ®
        """
        return await self.tts_client.openai_compatible_tts(
            text=input,
            voice=voice,
            response_format=response_format,
            speed=speed
        )

    async def audio_transcriptions_create(self,
                                        file,
                                        model: str = "whisper-1",
                                        **kwargs) -> Dict[str, Any]:
        """
        è¯­éŸ³è½¬æ–‡æœ¬ï¼ˆæš‚æœªå®ç°ï¼Œä¿æŒæ¥å£å…¼å®¹æ€§ï¼‰
        
        Args:
            file: éŸ³é¢‘æ–‡ä»¶
            model: ASRæ¨¡å‹åç§°
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            Dict: è½¬å½•ç»“æœ
        """
        # TODO: å®ç°ASRåŠŸèƒ½
        return {
            "text": "è¯­éŸ³è½¬æ–‡æœ¬åŠŸèƒ½æš‚æœªå®ç°"
        }

    # ==================== æµå¼å¯¹è¯+TTSé›†æˆ ====================
    
    async def stream_chat_with_tts(self,
                                 user_input: str,
                                 system_prompt: str = None,
                                 enable_tts: bool = True) -> AsyncGenerator[Dict[str, Any], None]:
        """
        æµå¼å¯¹è¯ + å®æ—¶TTS
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            enable_tts: æ˜¯å¦å¯ç”¨TTS
            
        Yields:
            Dict: åŒ…å«æ–‡æœ¬å’ŒéŸ³é¢‘çš„å“åº”
        """
        # æ”¶é›†æ‰€æœ‰æ–‡æœ¬ç”¨äºTTS
        full_text = ""
        text_chunks = []
        
        # æµå¼è·å–æ–‡æœ¬
        async for text_chunk in self.llm_client.stream_chat(user_input, system_prompt):
            full_text += text_chunk
            text_chunks.append(text_chunk)
            
            # è¿”å›æ–‡æœ¬å—
            yield {
                "type": "text",
                "content": text_chunk,
                "full_text": full_text
            }
        
        # ç”ŸæˆTTSéŸ³é¢‘
        if enable_tts and full_text.strip():
            try:
                audio_data = await self.tts_client.simple_tts(full_text)
                if audio_data:
                    # è¿”å›éŸ³é¢‘æ•°æ®ï¼ˆbase64ç¼–ç ï¼‰
                    audio_b64 = base64.b64encode(audio_data).decode('utf-8')
                    yield {
                        "type": "audio", 
                        "content": audio_b64,
                        "format": "mp3",
                        "text": full_text
                    }
            except Exception as e:
                yield {
                    "type": "error",
                    "content": f"TTSç”Ÿæˆå¤±è´¥: {str(e)}"
                }

    # ==================== æµ‹è¯•å’Œå·¥å…·æ–¹æ³• ====================
    
    def test_connection(self) -> Dict[str, bool]:
        """æµ‹è¯•æ‰€æœ‰ç»„ä»¶è¿æ¥"""
        return {
            "llm": self.llm_client.test_connection(),
            "tts": self.tts_client.test_connection()
        }
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        llm_status = self.llm_client.test_connection()
        tts_status = self.tts_client.test_connection()
        
        return {
            "status": "healthy" if (llm_status and tts_status) else "unhealthy",
            "components": {
                "llm": "ok" if llm_status else "error",
                "tts": "ok" if tts_status else "error"
            },
            "timestamp": int(time.time())
        }


# ==================== ä¾¿æ·åŒ…è£…ç±» ====================

class OpenAI:
    """OpenAI SDKå…¼å®¹çš„åŒ…è£…ç±»"""
    
    def __init__(self, api_key: str = None, base_url: str = None):
        """
        åˆå§‹åŒ–OpenAIå…¼å®¹å®¢æˆ·ç«¯
        
        Args:
            api_key: API Keyï¼ˆä¿æŒå…¼å®¹æ€§ï¼Œå®é™…ä»é…ç½®è¯»å–ï¼‰
            base_url: Base URLï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
        """
        self.client = OpenAICompatibleClient()
        self.chat = ChatCompletions(self.client)
        self.audio = Audio(self.client)


class ChatCompletions:
    """èŠå¤©å®ŒæˆAPI"""
    
    def __init__(self, client: OpenAICompatibleClient):
        self.client = client
    
    async def create(self, **kwargs):
        """åˆ›å»ºèŠå¤©å®Œæˆ"""
        stream = kwargs.get('stream', False)
        
        if stream:
            # è¿”å›å¼‚æ­¥ç”Ÿæˆå™¨
            return self.client.chat_completions_create(**kwargs)
        else:
            # è¿”å›å•ä¸ªç»“æœ
            async for result in self.client.chat_completions_create(**kwargs):
                return result


class Audio:
    """éŸ³é¢‘API"""
    
    def __init__(self, client: OpenAICompatibleClient):
        self.client = client
        self.speech = Speech(client)
        self.transcriptions = Transcriptions(client)


class Speech:
    """è¯­éŸ³åˆæˆAPI"""
    
    def __init__(self, client: OpenAICompatibleClient):
        self.client = client
    
    async def create(self, **kwargs):
        """åˆ›å»ºè¯­éŸ³"""
        return await self.client.audio_speech_create(**kwargs)


class Transcriptions:
    """è¯­éŸ³è½¬å½•API"""
    
    def __init__(self, client: OpenAICompatibleClient):
        self.client = client
    
    async def create(self, **kwargs):
        """åˆ›å»ºè½¬å½•"""
        return await self.client.audio_transcriptions_create(**kwargs)


# ==================== æµ‹è¯•ç”¨ä¾‹ ====================

async def test_openai_compatible():
    """æµ‹è¯•OpenAIå…¼å®¹æ¥å£"""
    print("ğŸ§ª æµ‹è¯•OpenAIå…¼å®¹æ¥å£...")
    
    try:
        # åˆ›å»ºå®¢æˆ·ç«¯
        client = OpenAI()
        
        # æµ‹è¯•è¿æ¥
        print("ğŸ” æµ‹è¯•è¿æ¥...")
        compatible_client = OpenAICompatibleClient()
        health = await compatible_client.health_check()
        print(f"å¥åº·çŠ¶æ€: {health}")
        
        if health['status'] != 'healthy':
            print("âŒ æœåŠ¡ä¸å¥åº·ï¼Œè¯·æ£€æŸ¥é…ç½®")
            return
        
        # æµ‹è¯•èŠå¤©å®Œæˆ
        print("\nğŸ’¬ æµ‹è¯•èŠå¤©å®Œæˆ...")
        response = await client.chat.create(
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹"},
                {"role": "user", "content": "ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹è‡ªå·±"}
            ],
            stream=False
        )
        print(f"å›å¤: {response['choices'][0]['message']['content']}")
        
        # æµ‹è¯•æµå¼èŠå¤©
        print("\nğŸ”„ æµ‹è¯•æµå¼èŠå¤©...")
        print("åŠ©æ‰‹: ", end="", flush=True)
        stream = await client.chat.create(
            messages=[
                {"role": "user", "content": "ç”¨ä¸€å¥è¯ä»‹ç»äººå·¥æ™ºèƒ½"}
            ],
            stream=True
        )
        
        async for chunk in stream:
            if chunk['choices'][0]['delta'].get('content'):
                print(chunk['choices'][0]['delta']['content'], end="", flush=True)
        print()
        
        # æµ‹è¯•TTS
        print("\nğŸµ æµ‹è¯•è¯­éŸ³åˆæˆ...")
        audio_data = await client.audio.speech.create(
            model="tts-1",
            input="è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•éŸ³é¢‘",
            voice="alloy"
        )
        
        if audio_data:
            with open("test_openai_tts.mp3", "wb") as f:
                f.write(audio_data)
            print(f"âœ… TTSéŸ³é¢‘ä¿å­˜æˆåŠŸ: test_openai_tts.mp3 ({len(audio_data)} å­—èŠ‚)")
        
        # æµ‹è¯•é›†æˆåŠŸèƒ½
        print("\nğŸ­ æµ‹è¯•æµå¼å¯¹è¯+TTSé›†æˆ...")
        integrated_stream = compatible_client.stream_chat_with_tts(
            user_input="ç®€å•ä»‹ç»ä¸€ä¸‹Pythonç¼–ç¨‹",
            enable_tts=True
        )
        
        full_audio_data = None
        async for chunk in integrated_stream:
            if chunk['type'] == 'text':
                print(chunk['content'], end="", flush=True)
            elif chunk['type'] == 'audio':
                # è§£ç éŸ³é¢‘æ•°æ®
                full_audio_data = base64.b64decode(chunk['content'])
                print(f"\nğŸµ æ”¶åˆ°é›†æˆTTSéŸ³é¢‘: {len(full_audio_data)} å­—èŠ‚")
        
        if full_audio_data:
            with open("test_integrated_tts.mp3", "wb") as f:
                f.write(full_audio_data)
            print("âœ… é›†æˆTTSéŸ³é¢‘ä¿å­˜æˆåŠŸ: test_integrated_tts.mp3")
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    await test_openai_compatible()


if __name__ == "__main__":
    asyncio.run(main()) 