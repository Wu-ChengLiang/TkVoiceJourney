#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIå›å¤ç”Ÿæˆå™¨ - çº¯OpenAIæµå¼å›å¤ç‰ˆæœ¬
ä¸“ä¸ºMadokaé¸ éšæ—¥å¼å±…é…’å±‹å®šåˆ¶
"""

import asyncio
import json
import logging
import re
import time
from typing import AsyncIterator, Optional
from dataclasses import dataclass

import httpx
from config import OPENAI_CONFIG, RESTAURANT_CONFIG

logger = logging.getLogger(__name__)


@dataclass
class ReplyResult:
    """å›å¤ç»“æœ"""
    text: str
    category: str = "AIç”Ÿæˆ"
    confidence: float = 0.9
    generation_time: float = 0.0


class OpenAIStreamReplyGenerator:
    """OpenAIæµå¼å›å¤ç”Ÿæˆå™¨ - Madokaé¸ éšä¸“ç”¨"""
    
    def __init__(self):
        self.client = None
        self.api_ready = False
        self._init_client()
        
        # ç³»ç»Ÿæç¤º - é’ˆå¯¹Madokaé¸ éšå®šåˆ¶
        self.system_prompt = f"""ä½ æ˜¯ã€{RESTAURANT_CONFIG['name']}ã€‘çš„æŠ–éŸ³å°åŠ©ç†ï¼Œéœ€è¦ç”Ÿæˆæ´»æ³¼æ¸©æš–ã€ä¸“ä¸šè´´å¿ƒçš„å›å¤ã€‚

é¤å…è¯¦ç»†ä¿¡æ¯ï¼š
- åç§°ï¼š{RESTAURANT_CONFIG['name']}
- ç±»å‹ï¼š{RESTAURANT_CONFIG['cuisine_type']}
- åœ°å€ï¼š{RESTAURANT_CONFIG['location']}
- ç”µè¯ï¼š{RESTAURANT_CONFIG['phone']}
- è¥ä¸šæ—¶é—´ï¼š{RESTAURANT_CONFIG['business_hours']}ï¼ˆ{RESTAURANT_CONFIG['status']}ï¼‰
- è¯„åˆ†ï¼š{RESTAURANT_CONFIG['rating']}
- äººå‡æ¶ˆè´¹ï¼šçº¦{RESTAURANT_CONFIG['avg_price']}å…ƒ
- æœåŠ¡ï¼š{'/'.join(RESTAURANT_CONFIG['services'])}

ç‰¹è‰²ä¸é£æ ¼ï¼š
{RESTAURANT_CONFIG['style']}

æ‹›ç‰Œç‰¹è‰²ï¼š
{', '.join(RESTAURANT_CONFIG['features'])}

å›å¤è¦æ±‚ï¼š
1. è¯­æ°”æ´»æ³¼å¯çˆ±ï¼Œç”¨"å®å­""äº²"ç­‰äº²åˆ‡ç§°å‘¼
2. å›å¤ç®€æ´æœ‰æ¸©åº¦ï¼Œå¸¦emojiï¼Œä¸è¶…è¿‡80å­—
3. ä½“ç°æ—¥å¼å±…é…’å±‹çš„æ°›å›´æ„Ÿå’Œä¸“ä¸šæ€§
4. é€‚å½“æåŠåˆ›æ„æ–™ç†ã€é¸¡å°¾é…’ç­‰ç‰¹è‰²
5. æ ¹æ®é—®é¢˜ç±»å‹ç»™å‡ºç²¾å‡†å›ç­”ï¼š
   - é¢„çº¦ï¼šè¯¢é—®äººæ•°æ—¶é—´ï¼Œæé†’çƒ­é—¨æ—¶æ®µéœ€æå‰
   - ä»·æ ¼ï¼šæåŠäººå‡æ¶ˆè´¹å’Œæ€§ä»·æ¯”
   - åœ°å€ï¼šå‡†ç¡®æä¾›åœ°å€å’Œäº¤é€šä¿¡æ¯
   - æ¨èï¼šé‡ç‚¹æ¨èé¹…è‚å¯¿å¸ã€åˆ›æ„é¸¡å°¾é…’ç­‰ç‰¹è‰²
   - è¥ä¸šæ—¶é—´ï¼š11:00-00:00ï¼Œå½“å‰è¥ä¸šä¸­
   - é£æ ¼ï¼šå¼ºè°ƒæ—¥å¼å±…é…’å±‹ä¸è¥¿å¼é…’å§çš„èåˆ

ç¤ºä¾‹ï¼š
"å®å­æƒ³è®¢å‡ äººä½å‘€ï¼Ÿæˆ‘ä»¬å®¶çš„é¹…è‚å¯¿å¸é…é¸¡å°¾é…’è¶…èµçš„~ ğŸ£ğŸ¸"

è¯·ç›´æ¥è¿”å›å›å¤æ–‡æœ¬ï¼Œä¸è¦åŒ…å«JSONæ ¼å¼ã€‚"""
    
    def _init_client(self):
        """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
        try:
            if not OPENAI_CONFIG["api_key"]:
                logger.warning("æœªé…ç½®OpenAI API Key")
                return
            
            self.client = httpx.AsyncClient(
                base_url=OPENAI_CONFIG["api_base"],
                headers={
                    "Authorization": f"Bearer {OPENAI_CONFIG['api_key']}",
                    "Content-Type": "application/json"
                },
                timeout=30.0
            )
            self.api_ready = True
            logger.info("âœ… OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"âŒ OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.api_ready = False
    
    async def generate_reply_stream(self, content: str) -> AsyncIterator[str]:
        """ç”Ÿæˆæµå¼å›å¤"""
        if not self.api_ready:
            yield "ç¨ç­‰å“¦ï¼Œå°åŠ©ç†é©¬ä¸Šå»é€šçŸ¥åº—å®¶ç¡®è®¤"
            return
        
        try:
            messages = [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": f"é¡¾å®¢é—®é¢˜ï¼š{content}\n\nè¯·ç”Ÿæˆä¸“ä¸šå›å¤ï¼š"}
            ]
            
            data = {
                "model": OPENAI_CONFIG["model"],
                "messages": messages,
                "max_tokens": OPENAI_CONFIG["max_tokens"],
                "temperature": OPENAI_CONFIG["temperature"],
                "stream": True
            }
            
            async with self.client.stream("POST", "/chat/completions", json=data) as response:
                response.raise_for_status()
                
                async for line in response.aiter_lines():
                    if line.startswith("data: "):
                        data_str = line[6:]
                        if data_str.strip() == "[DONE]":
                            break
                        
                        try:
                            chunk_data = json.loads(data_str)
                            if "choices" in chunk_data and chunk_data["choices"]:
                                delta = chunk_data["choices"][0].get("delta", {})
                                if "content" in delta:
                                    yield delta["content"]
                        except json.JSONDecodeError:
                            continue
                            
        except Exception as e:
            logger.error(f"OpenAIæµå¼ç”Ÿæˆå¤±è´¥: {e}")
            yield "ç¨ç­‰å“¦ï¼Œå°åŠ©ç†é©¬ä¸Šå»é€šçŸ¥åº—å®¶ç¡®è®¤"
    
    async def generate_reply(self, content: str) -> ReplyResult:
        """ç”Ÿæˆå®Œæ•´å›å¤"""
        start_time = time.time()
        reply_parts = []
        
        async for part in self.generate_reply_stream(content):
            reply_parts.append(part)
        
        reply_text = "".join(reply_parts).strip()
        generation_time = time.time() - start_time
        
        # æ¸…ç†å›å¤
        reply_text = self._clean_reply(reply_text)
        
        # æ£€æµ‹å›å¤ç±»åˆ«
        category = self._detect_reply_category(content)
        
        return ReplyResult(
            text=reply_text,
            category=category,
            confidence=0.9,
            generation_time=generation_time
        )
    
    def _clean_reply(self, text: str) -> str:
        """æ¸…ç†AIç”Ÿæˆçš„å›å¤"""
        if not text:
            return "ç¨ç­‰å“¦ï¼Œå°åŠ©ç†é©¬ä¸Šå»é€šçŸ¥åº—å®¶ç¡®è®¤"
        
        # ç§»é™¤å¤šä½™ç©ºç™½
        text = re.sub(r'\s+', ' ', text).strip()
        
        # ç§»é™¤å¯èƒ½çš„JSONåŒ…è£…
        if text.startswith('"') and text.endswith('"'):
            text = text[1:-1]
        
        # ç§»é™¤å›å¤å‰ç¼€
        text = re.sub(r'^(å›å¤[:ï¼š]?\s*|ç­”[:ï¼š]?\s*)', '', text)
        
        # é™åˆ¶é•¿åº¦
        if len(text) > 120:
            text = text[:120] + "..."
        
        return text
    
    def _detect_reply_category(self, content: str) -> str:
        """æ£€æµ‹å›å¤ç±»åˆ«"""
        content_lower = content.lower()
        
        if any(word in content_lower for word in ['é¢„çº¦', 'è®¢ä½', 'å®šä½', 'è®¢æ¡Œ']):
            return "é¢„çº¦å’¨è¯¢"
        elif any(word in content_lower for word in ['ä»·æ ¼', 'å¤šå°‘é’±', 'æ¶ˆè´¹', 'äººå‡']):
            return "ä»·æ ¼å’¨è¯¢"
        elif any(word in content_lower for word in ['åœ°å€', 'åœ¨å“ª', 'ä½ç½®', 'æ€ä¹ˆèµ°']):
            return "åœ°å€å’¨è¯¢"
        elif any(word in content_lower for word in ['æ¨è', 'ç‰¹è‰²', 'æ‹›ç‰Œ', 'å¥½åƒ']):
            return "èœå“æ¨è"
        elif any(word in content_lower for word in ['è¥ä¸šæ—¶é—´', 'å‡ ç‚¹', 'å¼€é—¨', 'å…³é—¨']):
            return "è¥ä¸šæ—¶é—´"
        elif any(word in content_lower for word in ['ç”µè¯', 'è”ç³»', 'å®¢æœ']):
            return "è”ç³»æ–¹å¼"
        else:
            return "é€šç”¨å’¨è¯¢"
    
    def get_stats(self) -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "api_ready": self.api_ready,
            "model": OPENAI_CONFIG["model"],
            "restaurant": RESTAURANT_CONFIG["name"]
        }
    
    async def close(self):
        """å…³é—­å®¢æˆ·ç«¯"""
        if self.client:
            await self.client.aclose()


class MadokaReplyGenerator:
    """Madokaé¸ éšä¸“ç”¨å›å¤ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.ai_generator = OpenAIStreamReplyGenerator()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_requests': 0,
            'ai_replies': 0,
            'fallback_replies': 0,
            'avg_generation_time': 0.0
        }
    
    async def generate_reply(self, content: str) -> ReplyResult:
        """ç”Ÿæˆå›å¤"""
        self.stats['total_requests'] += 1
        
        try:
            # ä½¿ç”¨AIç”Ÿæˆå›å¤
            if self.ai_generator.api_ready:
                self.stats['ai_replies'] += 1
                result = await self.ai_generator.generate_reply(content)
                
                # æ›´æ–°å¹³å‡ç”Ÿæˆæ—¶é—´
                self._update_avg_time(result.generation_time)
                
                return result
            
            # å…œåº•å›å¤
            self.stats['fallback_replies'] += 1
            return ReplyResult(
                text="ç¨ç­‰å“¦ï¼Œå°åŠ©ç†é©¬ä¸Šå»é€šçŸ¥åº—å®¶ç¡®è®¤",
                category="ç³»ç»Ÿå…œåº•",
                confidence=0.5
            )
            
        except Exception as e:
            logger.error(f"å›å¤ç”Ÿæˆå¤±è´¥: {e}")
            self.stats['fallback_replies'] += 1
            return ReplyResult(
                text="ç¨ç­‰å“¦ï¼Œå°åŠ©ç†é©¬ä¸Šå»é€šçŸ¥åº—å®¶ç¡®è®¤",
                category="é”™è¯¯å…œåº•",
                confidence=0.5
            )
    
    async def generate_reply_stream(self, content: str) -> AsyncIterator[str]:
        """ç”Ÿæˆæµå¼å›å¤"""
        try:
            # ç›´æ¥ä½¿ç”¨AIæµå¼ç”Ÿæˆ
            if self.ai_generator.api_ready:
                async for part in self.ai_generator.generate_reply_stream(content):
                    yield part
            else:
                # å…œåº•å›å¤
                yield "ç¨ç­‰å“¦ï¼Œå°åŠ©ç†é©¬ä¸Šå»é€šçŸ¥åº—å®¶ç¡®è®¤"
                
        except Exception as e:
            logger.error(f"æµå¼å›å¤ç”Ÿæˆå¤±è´¥: {e}")
            yield "ç¨ç­‰å“¦ï¼Œå°åŠ©ç†é©¬ä¸Šå»é€šçŸ¥åº—å®¶ç¡®è®¤"
    
    def _update_avg_time(self, generation_time: float):
        """æ›´æ–°å¹³å‡ç”Ÿæˆæ—¶é—´"""
        if self.stats['ai_replies'] > 1:
            self.stats['avg_generation_time'] = (
                (self.stats['avg_generation_time'] * (self.stats['ai_replies'] - 1) + generation_time) 
                / self.stats['ai_replies']
            )
        else:
            self.stats['avg_generation_time'] = generation_time
    
    def get_stats(self) -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total = self.stats['total_requests']
        base_stats = {
            **self.stats,
            'ai_rate': self.stats['ai_replies'] / total if total > 0 else 0,
            'fallback_rate': self.stats['fallback_replies'] / total if total > 0 else 0
        }
        
        # åˆå¹¶AIç”Ÿæˆå™¨ç»Ÿè®¡
        ai_stats = self.ai_generator.get_stats()
        return {**base_stats, **ai_stats}
    
    async def close(self):
        """å…³é—­èµ„æº"""
        await self.ai_generator.close()


# åˆ›å»ºå…¨å±€å®ä¾‹
def create_reply_generator() -> MadokaReplyGenerator:
    """åˆ›å»ºå›å¤ç”Ÿæˆå™¨å®ä¾‹"""
    return MadokaReplyGenerator()


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    async def test():
        generator = create_reply_generator()
        
        test_cases = [
            "ä»·æ ¼å¤šå°‘é’±",
            "æˆ‘æƒ³é¢„çº¦ä»Šæ™šçš„ä½ç½®",
            "ä½ ä»¬åœ°å€åœ¨å“ª",
            "è¥ä¸šæ—¶é—´å‡ ç‚¹åˆ°å‡ ç‚¹",
            "æ¨èä»€ä¹ˆç‰¹è‰²èœ",
            "æœ‰ä»€ä¹ˆå¥½çš„é¸¡å°¾é…’æ¨èå—",
            "é¹…è‚å¯¿å¸æ€ä¹ˆæ ·",
            "ä½ ä»¬è¿™ä¸ªæ—¥å¼å±…é…’å±‹æ€ä¹ˆæ ·ï¼Œç¯å¢ƒå¦‚ä½•"
        ]
        
        print(f"ğŸ£ æµ‹è¯• {RESTAURANT_CONFIG['name']} AIå›å¤ç³»ç»Ÿ")
        
        for i, content in enumerate(test_cases, 1):
            print(f"\n--- æµ‹è¯• {i} ---")
            print(f"é—®é¢˜: {content}")
            
            # æµ‹è¯•æ™®é€šå›å¤
            result = await generator.generate_reply(content)
            print(f"å›å¤: {result.text}")
            print(f"ç±»åˆ«: {result.category}")
            print(f"ç”Ÿæˆæ—¶é—´: {result.generation_time:.2f}s")
            
            # æµ‹è¯•æµå¼å›å¤
            print("æµå¼: ", end="")
            async for part in generator.generate_reply_stream(content):
                print(part, end="", flush=True)
            print()
        
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯: {generator.get_stats()}")
        await generator.close()
    
    asyncio.run(test())
