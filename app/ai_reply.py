#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIå›å¤ç”Ÿæˆå™¨
ä½¿ç”¨OpenAIæµå¼è¾“å‡ºå’Œå›ºå®šæ¨¡æ¿å›å¤
"""

import asyncio
import hashlib
import json
import logging
import random
import re
import time
from typing import AsyncIterator, Dict, List, Optional, Tuple
from dataclasses import dataclass

import httpx
from config import (
    OPENAI_CONFIG, 
    TEMPLATE_REPLIES, 
    HIGH_VALUE_KEYWORDS, 
    RESTAURANT_CONFIG
)

logger = logging.getLogger(__name__)


@dataclass
class ReplyResult:
    """å›å¤ç»“æœ"""
    text: str
    is_template: bool = False
    category: str = "é»˜è®¤"
    confidence: float = 0.0
    generation_time: float = 0.0


class TemplateReplyGenerator:
    """æ¨¡æ¿å›å¤ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.template_cache = {}
        self.usage_stats = {category: 0 for category in TEMPLATE_REPLIES.keys()}
    
    def detect_category(self, content: str) -> str:
        """æ£€æµ‹å¼¹å¹•å†…å®¹ç±»åˆ«"""
        content = content.lower()
        
        # æŒ‰ä¼˜å…ˆçº§æ£€æµ‹å…³é”®è¯
        for category, keywords in HIGH_VALUE_KEYWORDS.items():
            for keyword in keywords:
                if keyword in content:
                    return category
        
        return "é»˜è®¤"
    
    def generate_template_reply(self, content: str, category: str = None) -> ReplyResult:
        """ç”Ÿæˆæ¨¡æ¿å›å¤"""
        if not category:
            category = self.detect_category(content)
        
        # è·å–è¯¥ç±»åˆ«çš„æ¨¡æ¿
        templates = TEMPLATE_REPLIES.get(category, TEMPLATE_REPLIES["é»˜è®¤"])
        
        # éšæœºé€‰æ‹©ä¸€ä¸ªæ¨¡æ¿ï¼ˆé¿å…é‡å¤ï¼‰
        self.usage_stats[category] += 1
        template_index = self.usage_stats[category] % len(templates)
        reply_text = templates[template_index]
        
        # æ›¿æ¢å ä½ç¬¦
        reply_text = self._replace_placeholders(reply_text, category)
        
        return ReplyResult(
            text=reply_text,
            is_template=True,
            category=category,
            confidence=0.8,
            generation_time=0.01
        )
    
    def _replace_placeholders(self, text: str, category: str) -> str:
        """æ›¿æ¢æ¨¡æ¿ä¸­çš„å ä½ç¬¦"""
        replacements = {
            'xx': RESTAURANT_CONFIG['avg_price'],
            'ç¾å‘³é¤å…': RESTAURANT_CONFIG['name'],
            'XXé¤å…': RESTAURANT_CONFIG['name'],
            'xxèœç³»': RESTAURANT_CONFIG['cuisine_type'],
            'xxå…¬é‡Œ': '5',
            'xxç«™': 'å¸‚ä¸­å¿ƒ',
            'xxå¹³å°': 'ç¾å›¢/é¥¿äº†ä¹ˆ',
            'xxå…ƒèµ·': f"{RESTAURANT_CONFIG['avg_price']}å…ƒèµ·"
        }
        
        for placeholder, replacement in replacements.items():
            text = text.replace(placeholder, replacement)
        
        return text


class OpenAIStreamReplyGenerator:
    """OpenAIæµå¼å›å¤ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.client = None
        self.api_ready = False
        self._init_client()
        
        # ç³»ç»Ÿæç¤º
        self.system_prompt = f"""ä½ æ˜¯ã€{RESTAURANT_CONFIG['name']}ã€‘çš„æŠ–éŸ³å°åŠ©ç†ï¼Œéœ€è¦ç”Ÿæˆæ´»æ³¼æ¸©æš–ã€ä¸“ä¸šè´´å¿ƒçš„å›å¤ã€‚

é¤å…ç‰¹è‰²ï¼š
- ä¸»æ‰“{RESTAURANT_CONFIG['cuisine_type']}
- æä¾›{'/'.join(RESTAURANT_CONFIG['services'])}æœåŠ¡
- äººå‡æ¶ˆè´¹çº¦{RESTAURANT_CONFIG['avg_price']}å…ƒ
- æ‹›ç‰Œèœï¼š{', '.join(RESTAURANT_CONFIG['features'])}

å›å¤è¦æ±‚ï¼š
1. è¯­æ°”æ´»æ³¼å¯çˆ±ï¼Œç”¨"å®å­""äº²"ç­‰äº²åˆ‡ç§°å‘¼
2. å›å¤ç®€æ´æœ‰æ¸©åº¦ï¼Œå¸¦emojiï¼Œä¸è¶…è¿‡50å­—
3. å…³é”®ä¿¡æ¯ç”¨"xx"ä»£æ›¿ï¼ˆå¦‚"äººå‡xxå…ƒèµ·~"ï¼‰
4. é€‚å½“ä½¿ç”¨é¤é¥®è¯æœ¯ï¼š"çˆ†æ¬¾èœå“""æ‹›ç‰Œå¿…ç‚¹"ç­‰

ç¤ºä¾‹ï¼š
"å®å­æƒ³è®¢å‡ äººä½å‘€ï¼Ÿå‘¨æœ«å»ºè®®æå‰2å¤©é¢„çº¦å“¦~ ğŸŒ¸"

è¯·ç›´æ¥è¿”å›å›å¤æ–‡æœ¬ï¼Œä¸è¦åŒ…å«JSONæ ¼å¼ã€‚"""
    
    def _init_client(self):
        """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
        try:
            if not OPENAI_CONFIG["api_key"]:
                logger.warning("æœªé…ç½®OpenAI API Key")
                return
            
            self.client = httpx.AsyncClient(
                base_url=OPENAI_CONFIG["api_base"],
                headers={
                    "Authorization": f"Bearer {OPENAI_CONFIG['api_key']}",
                    "Content-Type": "application/json"
                },
                timeout=30.0
            )
            self.api_ready = True
            logger.info("âœ… OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"âŒ OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.api_ready = False
    
    async def generate_reply_stream(self, content: str) -> AsyncIterator[str]:
        """ç”Ÿæˆæµå¼å›å¤"""
        if not self.api_ready:
            yield "ç¨ç­‰å“¦ï¼Œå°åŠ©ç†é©¬ä¸Šå»é€šçŸ¥åº—å®¶ç¡®è®¤~"
            return
        
        try:
            messages = [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": f"é¡¾å®¢é—®é¢˜ï¼š{content}\n\nè¯·ç”Ÿæˆä¸“ä¸šå›å¤ï¼š"}
            ]
            
            data = {
                "model": OPENAI_CONFIG["model"],
                "messages": messages,
                "max_tokens": OPENAI_CONFIG["max_tokens"],
                "temperature": OPENAI_CONFIG["temperature"],
                "stream": True
            }
            
            async with self.client.stream("POST", "/chat/completions", json=data) as response:
                response.raise_for_status()
                
                async for line in response.aiter_lines():
                    if line.startswith("data: "):
                        data_str = line[6:]
                        if data_str.strip() == "[DONE]":
                            break
                        
                        try:
                            chunk_data = json.loads(data_str)
                            if "choices" in chunk_data and chunk_data["choices"]:
                                delta = chunk_data["choices"][0].get("delta", {})
                                if "content" in delta:
                                    yield delta["content"]
                        except json.JSONDecodeError:
                            continue
                            
        except Exception as e:
            logger.error(f"OpenAIæµå¼ç”Ÿæˆå¤±è´¥: {e}")
            yield "ç¨ç­‰å“¦ï¼Œå°åŠ©ç†é©¬ä¸Šå»é€šçŸ¥åº—å®¶ç¡®è®¤~"
    
    async def generate_reply(self, content: str) -> ReplyResult:
        """ç”Ÿæˆå®Œæ•´å›å¤"""
        start_time = time.time()
        reply_parts = []
        
        async for part in self.generate_reply_stream(content):
            reply_parts.append(part)
        
        reply_text = "".join(reply_parts).strip()
        generation_time = time.time() - start_time
        
        # æ¸…ç†å›å¤
        reply_text = self._clean_reply(reply_text)
        
        return ReplyResult(
            text=reply_text,
            is_template=False,
            category="AIç”Ÿæˆ",
            confidence=0.9,
            generation_time=generation_time
        )
    
    def _clean_reply(self, text: str) -> str:
        """æ¸…ç†AIç”Ÿæˆçš„å›å¤"""
        if not text:
            return "ç¨ç­‰å“¦ï¼Œå°åŠ©ç†é©¬ä¸Šå»é€šçŸ¥åº—å®¶ç¡®è®¤~"
        
        # ç§»é™¤å¤šä½™ç©ºç™½
        text = re.sub(r'\s+', ' ', text).strip()
        
        # ç§»é™¤å¯èƒ½çš„JSONåŒ…è£…
        if text.startswith('"') and text.endswith('"'):
            text = text[1:-1]
        
        # ç§»é™¤å›å¤å‰ç¼€
        text = re.sub(r'^(å›å¤[:ï¼š]?\s*|ç­”[:ï¼š]?\s*)', '', text)
        
        # é™åˆ¶é•¿åº¦
        if len(text) > 100:
            text = text[:100] + "..."
        
        return text
    
    async def close(self):
        """å…³é—­å®¢æˆ·ç«¯"""
        if self.client:
            await self.client.aclose()


class SmartReplyGenerator:
    """æ™ºèƒ½å›å¤ç”Ÿæˆå™¨ï¼ˆæ¨¡æ¿+AIæ··åˆï¼‰"""
    
    def __init__(self):
        self.template_generator = TemplateReplyGenerator()
        self.ai_generator = OpenAIStreamReplyGenerator()
        
        # ç­–ç•¥é…ç½®
        self.template_threshold = 0.7  # æ¨¡æ¿å›å¤é˜ˆå€¼
        self.ai_fallback = True  # AIå›å¤å…œåº•
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_requests': 0,
            'template_replies': 0,
            'ai_replies': 0,
            'fallback_replies': 0
        }
    
    async def generate_reply(self, content: str) -> ReplyResult:
        """æ™ºèƒ½ç”Ÿæˆå›å¤"""
        self.stats['total_requests'] += 1
        
        try:
            # 1. å°è¯•æ¨¡æ¿å›å¤
            category = self.template_generator.detect_category(content)
            
            # é«˜ç½®ä¿¡åº¦ä½¿ç”¨æ¨¡æ¿å›å¤
            if category != "é»˜è®¤" and self._should_use_template(content, category):
                self.stats['template_replies'] += 1
                return self.template_generator.generate_template_reply(content, category)
            
            # 2. ä½¿ç”¨AIç”Ÿæˆå›å¤
            if self.ai_generator.api_ready:
                self.stats['ai_replies'] += 1
                return await self.ai_generator.generate_reply(content)
            
            # 3. å…œåº•ä½¿ç”¨æ¨¡æ¿å›å¤
            self.stats['fallback_replies'] += 1
            return self.template_generator.generate_template_reply(content, "é»˜è®¤")
            
        except Exception as e:
            logger.error(f"å›å¤ç”Ÿæˆå¤±è´¥: {e}")
            self.stats['fallback_replies'] += 1
            return ReplyResult(
                text="ç¨ç­‰å“¦ï¼Œå°åŠ©ç†é©¬ä¸Šå»é€šçŸ¥åº—å®¶ç¡®è®¤~",
                is_template=True,
                category="é”™è¯¯å…œåº•",
                confidence=0.5
            )
    
    async def generate_reply_stream(self, content: str) -> AsyncIterator[str]:
        """ç”Ÿæˆæµå¼å›å¤"""
        try:
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨æ¨¡æ¿å›å¤
            category = self.template_generator.detect_category(content)
            
            if category != "é»˜è®¤" and self._should_use_template(content, category):
                # ç«‹å³è¿”å›æ¨¡æ¿å›å¤
                template_result = self.template_generator.generate_template_reply(content, category)
                yield template_result.text
                return
            
            # ä½¿ç”¨AIæµå¼ç”Ÿæˆ
            if self.ai_generator.api_ready:
                async for part in self.ai_generator.generate_reply_stream(content):
                    yield part
            else:
                # å…œåº•æ¨¡æ¿å›å¤
                fallback_result = self.template_generator.generate_template_reply(content, "é»˜è®¤")
                yield fallback_result.text
                
        except Exception as e:
            logger.error(f"æµå¼å›å¤ç”Ÿæˆå¤±è´¥: {e}")
            yield "ç¨ç­‰å“¦ï¼Œå°åŠ©ç†é©¬ä¸Šå»é€šçŸ¥åº—å®¶ç¡®è®¤~"
    
    def _should_use_template(self, content: str, category: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨æ¨¡æ¿å›å¤"""
        # ç®€å•é—®é¢˜ä¼˜å…ˆä½¿ç”¨æ¨¡æ¿
        simple_patterns = [
            r'^.{0,10}(ä»·æ ¼|å¤šå°‘é’±|è´¹ç”¨)',  # ç®€çŸ­çš„ä»·æ ¼è¯¢é—®
            r'^.{0,10}(åœ°å€|åœ¨å“ª|ä½ç½®)',   # ç®€çŸ­çš„åœ°å€è¯¢é—®
            r'^.{0,10}(è¥ä¸šæ—¶é—´|å‡ ç‚¹)',    # ç®€çŸ­çš„æ—¶é—´è¯¢é—®
            r'^.{0,8}(é¢„çº¦|è®¢ä½)',        # ç®€çŸ­çš„é¢„çº¦
        ]
        
        for pattern in simple_patterns:
            if re.search(pattern, content):
                return True
        
        # å¯¹äºå¤æ‚é—®é¢˜ï¼Œä½¿ç”¨AIç”Ÿæˆ
        return len(content) < 15
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total = self.stats['total_requests']
        if total == 0:
            return self.stats
        
        return {
            **self.stats,
            'template_rate': self.stats['template_replies'] / total,
            'ai_rate': self.stats['ai_replies'] / total,
            'fallback_rate': self.stats['fallback_replies'] / total
        }
    
    async def close(self):
        """å…³é—­èµ„æº"""
        await self.ai_generator.close()


# åˆ›å»ºå…¨å±€å®ä¾‹
def create_reply_generator() -> SmartReplyGenerator:
    """åˆ›å»ºå›å¤ç”Ÿæˆå™¨å®ä¾‹"""
    return SmartReplyGenerator()


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    async def test():
        generator = create_reply_generator()
        
        test_cases = [
            "ä»·æ ¼å¤šå°‘é’±",
            "æˆ‘æƒ³é¢„çº¦",
            "ä½ ä»¬åœ°å€åœ¨å“ª",
            "è¥ä¸šæ—¶é—´å‡ ç‚¹åˆ°å‡ ç‚¹",
            "æ¨èä»€ä¹ˆèœ",
            "ä½ ä»¬è¿™ä¸ªå·èœæ­£å®—å—ï¼Œæˆ‘æƒ³äº†è§£ä¸€ä¸‹ç‰¹è‰²èœå“å’Œç”¨é¤ç¯å¢ƒ"
        ]
        
        for content in test_cases:
            print(f"\né—®é¢˜: {content}")
            
            # æµ‹è¯•æ™®é€šå›å¤
            result = await generator.generate_reply(content)
            print(f"å›å¤: {result.text}")
            print(f"ç±»å‹: {'æ¨¡æ¿' if result.is_template else 'AI'}")
            print(f"ç±»åˆ«: {result.category}")
            
            # æµ‹è¯•æµå¼å›å¤
            print("æµå¼: ", end="")
            async for part in generator.generate_reply_stream(content):
                print(part, end="", flush=True)
            print()
        
        print(f"\nç»Ÿè®¡ä¿¡æ¯: {generator.get_stats()}")
        await generator.close()
    
    asyncio.run(test())
