#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIå›å¤ç”Ÿæˆå™¨
ä½¿ç”¨OpenAIæµå¼è¾“å‡ºå’Œå›ºå®šæ¨¡æ¿å›å¤ï¼ˆæ¨¡æ¿åŠŸèƒ½å·²æ³¨é‡Šï¼‰
"""

import asyncio
import hashlib
import json
import logging
import random
import re
import time
from typing import AsyncIterator, Dict, List, Optional, Tuple
from dataclasses import dataclass

import httpx
from config import (
    OPENAI_CONFIG, 
    # TEMPLATE_REPLIES,  # æ¨¡æ¿å›å¤å·²æ³¨é‡Š
    # HIGH_VALUE_KEYWORDS,  # é«˜ä»·å€¼å…³é”®è¯å·²æ³¨é‡Š
    RESTAURANT_CONFIG
)

logger = logging.getLogger(__name__)


@dataclass
class ReplyResult:
    """å›å¤ç»“æœ"""
    text: str
    is_template: bool = False
    category: str = "AIç”Ÿæˆ"
    confidence: float = 0.9
    generation_time: float = 0.0


# class TemplateReplyGenerator:
#     """æ¨¡æ¿å›å¤ç”Ÿæˆå™¨ - å·²æ³¨é‡Šç¦ç”¨"""
#     
#     def __init__(self):
#         self.template_cache = {}
#         self.usage_stats = {category: 0 for category in TEMPLATE_REPLIES.keys()}
#     
#     def detect_category(self, content: str) -> str:
#         """æ£€æµ‹å¼¹å¹•å†…å®¹ç±»åˆ«"""
#         content = content.lower()
#         
#         # æŒ‰ä¼˜å…ˆçº§æ£€æµ‹å…³é”®è¯
#         for category, keywords in HIGH_VALUE_KEYWORDS.items():
#             for keyword in keywords:
#                 if keyword in content:
#                     return category
#         
#         return "é»˜è®¤"
#     
#     def generate_template_reply(self, content: str, category: str = None) -> ReplyResult:
#         """ç”Ÿæˆæ¨¡æ¿å›å¤"""
#         if not category:
#             category = self.detect_category(content)
#         
#         # è·å–è¯¥ç±»åˆ«çš„æ¨¡æ¿
#         templates = TEMPLATE_REPLIES.get(category, TEMPLATE_REPLIES["é»˜è®¤"])
#         
#         # éšæœºé€‰æ‹©ä¸€ä¸ªæ¨¡æ¿ï¼ˆé¿å…é‡å¤ï¼‰
#         self.usage_stats[category] += 1
#         template_index = self.usage_stats[category] % len(templates)
#         reply_text = templates[template_index]
#         
#         # æ›¿æ¢å ä½ç¬¦
#         reply_text = self._replace_placeholders(reply_text, category)
#         
#         return ReplyResult(
#             text=reply_text,
#             is_template=True,
#             category=category,
#             confidence=0.8,
#             generation_time=0.01
#         )
#     
#     def _replace_placeholders(self, text: str, category: str) -> str:
#         """æ›¿æ¢æ¨¡æ¿ä¸­çš„å ä½ç¬¦"""
#         replacements = {
#             'xx': RESTAURANT_CONFIG['avg_price'],
#             'ç¾å‘³é¤å…': RESTAURANT_CONFIG['name'],
#             'XXé¤å…': RESTAURANT_CONFIG['name'],
#             'xxèœç³»': RESTAURANT_CONFIG['cuisine_type'],
#             'xxå…¬é‡Œ': '5',
#             'xxç«™': 'å¸‚ä¸­å¿ƒ',
#             'xxå¹³å°': 'ç¾å›¢/é¥¿äº†ä¹ˆ',
#             'xxå…ƒèµ·': f"{RESTAURANT_CONFIG['avg_price']}å…ƒèµ·"
#         }
#         
#         for placeholder, replacement in replacements.items():
#             text = text.replace(placeholder, replacement)
#         
#         return text


class OpenAIStreamReplyGenerator:
    """OpenAIæµå¼å›å¤ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.client = None
        self.api_ready = False
        self._init_client()
        
        # ç³»ç»Ÿæç¤º - æ ¹æ®æœ€æ–°é…ç½®æ–‡ä»¶æ›´æ–°
        self.system_prompt = f"""ä½ æ˜¯ã€{RESTAURANT_CONFIG['name']}ã€‘çš„æŠ–éŸ³å°åŠ©ç†ï¼Œéœ€è¦ç”Ÿæˆæ´»æ³¼æ¸©æš–ã€ä¸“ä¸šè´´å¿ƒçš„å›å¤ã€‚

é¤å…è¯¦ç»†ä¿¡æ¯ï¼š
- åç§°ï¼š{RESTAURANT_CONFIG['name']}
- ç±»å‹ï¼š{RESTAURANT_CONFIG['cuisine_type']}
- åœ°å€ï¼š{RESTAURANT_CONFIG['location']}
- ç”µè¯ï¼š{RESTAURANT_CONFIG['phone']}
- è¥ä¸šæ—¶é—´ï¼š{RESTAURANT_CONFIG['business_hours']}ï¼ˆ{RESTAURANT_CONFIG['status']}ï¼‰
- è¯„åˆ†ï¼š{RESTAURANT_CONFIG['rating']}
- äººå‡æ¶ˆè´¹ï¼šçº¦{RESTAURANT_CONFIG['avg_price']}å…ƒ
- æœåŠ¡ï¼š{'/'.join(RESTAURANT_CONFIG['services'])}

ç‰¹è‰²ä¸é£æ ¼ï¼š
{RESTAURANT_CONFIG['style']}

æ‹›ç‰Œç‰¹è‰²ï¼š
{', '.join(RESTAURANT_CONFIG['features'])}

ç‰¹æƒ å¥—é¤ï¼š
{RESTAURANT_CONFIG.get('set meal', '')}

å›å¤è¦æ±‚ï¼š
1. è¯­æ°”æ´»æ³¼å¯çˆ±ï¼Œç”¨"å®å­""äº²"ç­‰äº²åˆ‡ç§°å‘¼
2. å›å¤ç”ŸåŠ¨æœ‰è¶£ï¼Œä¸å¸¦emojiï¼Œ12~30å­—å·¦å³ï¼Œå¯ä»¥åƒæ˜¯ä¿çš®çš„é‚»å®¶å¥³å­©ï¼Œ
3. é€‚å½“æåŠç‰¹è‰²èœå“ã€å¥—é¤ç­‰äº®ç‚¹

è¯·ç›´æ¥è¿”å›å›å¤æ–‡æœ¬ï¼Œä¸è¦åŒ…å«JSONæ ¼å¼ã€‚

"""
    
    def _init_client(self):
        """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
        try:
            if not OPENAI_CONFIG["api_key"]:
                logger.warning("æœªé…ç½®OpenAI API Key")
                return
            
            self.client = httpx.AsyncClient(
                base_url=OPENAI_CONFIG["api_base"],
                headers={
                    "Authorization": f"Bearer {OPENAI_CONFIG['api_key']}",
                    "Content-Type": "application/json"
                },
                timeout=30.0
            )
            self.api_ready = True
            logger.info("âœ… OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"âŒ OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.api_ready = False
    
    async def generate_reply_stream(self, content: str) -> AsyncIterator[str]:
        """ç”Ÿæˆæµå¼å›å¤"""
        if not self.api_ready:
            yield "ç¨ç­‰å“¦ï¼Œå°åŠ©ç†é©¬ä¸Šå»é€šçŸ¥åº—å®¶ç¡®è®¤~"
            return
        
        try:
            messages = [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": f"é¡¾å®¢é—®é¢˜ï¼š{content}\n\nè¯·ç”Ÿæˆä¸“ä¸šå›å¤ï¼š"}
            ]
            
            data = {
                "model": OPENAI_CONFIG["model"],
                "messages": messages,
                "max_tokens": OPENAI_CONFIG["max_tokens"],
                "temperature": OPENAI_CONFIG["temperature"],
                "stream": True
            }
            
            async with self.client.stream("POST", "/chat/completions", json=data) as response:
                response.raise_for_status()
                
                async for line in response.aiter_lines():
                    if line.startswith("data: "):
                        data_str = line[6:]
                        if data_str.strip() == "[DONE]":
                            break
                        
                        try:
                            chunk_data = json.loads(data_str)
                            if "choices" in chunk_data and chunk_data["choices"]:
                                delta = chunk_data["choices"][0].get("delta", {})
                                if "content" in delta:
                                    yield delta["content"]
                        except json.JSONDecodeError:
                            continue
                            
        except Exception as e:
            logger.error(f"OpenAIæµå¼ç”Ÿæˆå¤±è´¥: {e}")
            yield "ç¨ç­‰å“¦ï¼Œå°åŠ©ç†é©¬ä¸Šå»é€šçŸ¥åº—å®¶ç¡®è®¤~ ğŸ¤—"
    
    async def generate_reply(self, content: str) -> ReplyResult:
        """ç”Ÿæˆå®Œæ•´å›å¤"""
        start_time = time.time()
        reply_parts = []
        
        async for part in self.generate_reply_stream(content):
            reply_parts.append(part)
        
        reply_text = "".join(reply_parts).strip()
        generation_time = time.time() - start_time
        
        # æ¸…ç†å›å¤
        reply_text = self._clean_reply(reply_text)
        
        # æ£€æµ‹å›å¤ç±»åˆ«
        category = self._detect_reply_category(content)
        
        return ReplyResult(
            text=reply_text,
            is_template=False,
            category=category,
            confidence=0.9,
            generation_time=generation_time
        )
    
    def _clean_reply(self, text: str) -> str:
        """æ¸…ç†AIç”Ÿæˆçš„å›å¤"""
        if not text:
            return "ç¨ç­‰å“¦ï¼Œå°åŠ©ç†é©¬ä¸Šå»é€šçŸ¥åº—å®¶ç¡®è®¤~ ğŸ¤—"
        
        # ç§»é™¤å¤šä½™ç©ºç™½
        text = re.sub(r'\s+', ' ', text).strip()
        
        # ç§»é™¤å¯èƒ½çš„JSONåŒ…è£…
        if text.startswith('"') and text.endswith('"'):
            text = text[1:-1]
        
        # ç§»é™¤å›å¤å‰ç¼€
        text = re.sub(r'^(å›å¤[:ï¼š]?\s*|ç­”[:ï¼š]?\s*)', '', text)
        
        # é™åˆ¶é•¿åº¦
        if len(text) > 120:
            text = text[:120] + "..."
        
        return text
    
    def _detect_reply_category(self, content: str) -> str:
        """æ£€æµ‹å›å¤ç±»åˆ«"""
        content_lower = content.lower()
        
        if any(word in content_lower for word in ['é¢„çº¦', 'è®¢ä½', 'å®šä½', 'è®¢æ¡Œ']):
            return "é¢„çº¦å’¨è¯¢"
        elif any(word in content_lower for word in ['ä»·æ ¼', 'å¤šå°‘é’±', 'æ¶ˆè´¹', 'äººå‡', 'å¥—é¤']):
            return "ä»·æ ¼å’¨è¯¢"
        elif any(word in content_lower for word in ['åœ°å€', 'åœ¨å“ª', 'ä½ç½®', 'æ€ä¹ˆèµ°']):
            return "åœ°å€å’¨è¯¢"
        elif any(word in content_lower for word in ['æ¨è', 'ç‰¹è‰²', 'æ‹›ç‰Œ', 'å¥½åƒ']):
            return "èœå“æ¨è"
        elif any(word in content_lower for word in ['è¥ä¸šæ—¶é—´', 'å‡ ç‚¹', 'å¼€é—¨', 'å…³é—¨']):
            return "è¥ä¸šæ—¶é—´"
        elif any(word in content_lower for word in ['ç”µè¯', 'è”ç³»', 'å®¢æœ']):
            return "è”ç³»æ–¹å¼"
        else:
            return "é€šç”¨å’¨è¯¢"
    
    def get_stats(self) -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "api_ready": self.api_ready,
            "model": OPENAI_CONFIG["model"],
            "restaurant": RESTAURANT_CONFIG["name"]
        }
    
    async def close(self):
        """å…³é—­å®¢æˆ·ç«¯"""
        if self.client:
            await self.client.aclose()


class SmartReplyGenerator:
    """æ™ºèƒ½å›å¤ç”Ÿæˆå™¨ï¼ˆå½“å‰åªä½¿ç”¨AIï¼Œæ¨¡æ¿åŠŸèƒ½å·²æ³¨é‡Šï¼‰"""
    
    def __init__(self):
        # self.template_generator = TemplateReplyGenerator()  # æ¨¡æ¿ç”Ÿæˆå™¨å·²æ³¨é‡Š
        self.ai_generator = OpenAIStreamReplyGenerator()
        
        # ç­–ç•¥é…ç½®
        # self.template_threshold = 0.7  # æ¨¡æ¿å›å¤é˜ˆå€¼ - å·²æ³¨é‡Š
        self.ai_fallback = True  # AIå›å¤å…œåº•
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_requests': 0,
            # 'template_replies': 0,  # æ¨¡æ¿å›å¤ç»Ÿè®¡å·²æ³¨é‡Š
            'ai_replies': 0,
            'fallback_replies': 0,
            'avg_generation_time': 0.0
        }
    
    async def generate_reply(self, content: str) -> ReplyResult:
        """æ™ºèƒ½ç”Ÿæˆå›å¤ï¼ˆå½“å‰åªä½¿ç”¨AIï¼‰"""
        self.stats['total_requests'] += 1
        
        try:
            # æ¨¡æ¿å›å¤åŠŸèƒ½å·²æ³¨é‡Šï¼Œç›´æ¥ä½¿ç”¨AIç”Ÿæˆ
            # # 1. å°è¯•æ¨¡æ¿å›å¤
            # category = self.template_generator.detect_category(content)
            # 
            # # é«˜ç½®ä¿¡åº¦ä½¿ç”¨æ¨¡æ¿å›å¤
            # if category != "é»˜è®¤" and self._should_use_template(content, category):
            #     self.stats['template_replies'] += 1
            #     return self.template_generator.generate_template_reply(content, category)
            
            # ä½¿ç”¨AIç”Ÿæˆå›å¤
            if self.ai_generator.api_ready:
                self.stats['ai_replies'] += 1
                result = await self.ai_generator.generate_reply(content)
                
                # æ›´æ–°å¹³å‡ç”Ÿæˆæ—¶é—´
                self._update_avg_time(result.generation_time)
                
                return result
            
            # å…œåº•å›å¤
            self.stats['fallback_replies'] += 1
            return ReplyResult(
                text="ç¨ç­‰å“¦ï¼Œå°åŠ©ç†é©¬ä¸Šå»é€šçŸ¥åº—å®¶ç¡®è®¤~ ğŸ¤—",
                is_template=False,
                category="ç³»ç»Ÿå…œåº•",
                confidence=0.5
            )
            
        except Exception as e:
            logger.error(f"å›å¤ç”Ÿæˆå¤±è´¥: {e}")
            self.stats['fallback_replies'] += 1
            return ReplyResult(
                text="ç¨ç­‰å“¦ï¼Œå°åŠ©ç†é©¬ä¸Šå»é€šçŸ¥åº—å®¶ç¡®è®¤~ ğŸ¤—",
                is_template=False,
                category="é”™è¯¯å…œåº•",
                confidence=0.5
            )
    
    async def generate_reply_stream(self, content: str) -> AsyncIterator[str]:
        """ç”Ÿæˆæµå¼å›å¤ï¼ˆå½“å‰åªä½¿ç”¨AIï¼‰"""
        try:
            # æ¨¡æ¿å›å¤åŠŸèƒ½å·²æ³¨é‡Šï¼Œç›´æ¥ä½¿ç”¨AIæµå¼ç”Ÿæˆ
            # # æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨æ¨¡æ¿å›å¤
            # category = self.template_generator.detect_category(content)
            # 
            # if category != "é»˜è®¤" and self._should_use_template(content, category):
            #     # ç«‹å³è¿”å›æ¨¡æ¿å›å¤
            #     template_result = self.template_generator.generate_template_reply(content, category)
            #     yield template_result.text
            #     return
            
            # ä½¿ç”¨AIæµå¼ç”Ÿæˆ
            if self.ai_generator.api_ready:
                async for part in self.ai_generator.generate_reply_stream(content):
                    yield part
            else:
                # å…œåº•å›å¤
                yield "ç¨ç­‰å“¦ï¼Œå°åŠ©ç†é©¬ä¸Šå»é€šçŸ¥åº—å®¶ç¡®è®¤~ ğŸ¤—"
                
        except Exception as e:
            logger.error(f"æµå¼å›å¤ç”Ÿæˆå¤±è´¥: {e}")
            yield "ç¨ç­‰å“¦ï¼Œå°åŠ©ç†é©¬ä¸Šå»é€šçŸ¥åº—å®¶ç¡®è®¤~ ğŸ¤—"
    
    # def _should_use_template(self, content: str, category: str) -> bool:
    #     """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨æ¨¡æ¿å›å¤ - å·²æ³¨é‡Š"""
    #     # ç®€å•é—®é¢˜ä¼˜å…ˆä½¿ç”¨æ¨¡æ¿
    #     simple_patterns = [
    #         r'^.{0,10}(ä»·æ ¼|å¤šå°‘é’±|è´¹ç”¨)',  # ç®€çŸ­çš„ä»·æ ¼è¯¢é—®
    #         r'^.{0,10}(åœ°å€|åœ¨å“ª|ä½ç½®)',   # ç®€çŸ­çš„åœ°å€è¯¢é—®
    #         r'^.{0,10}(è¥ä¸šæ—¶é—´|å‡ ç‚¹)',    # ç®€çŸ­çš„æ—¶é—´è¯¢é—®
    #         r'^.{0,8}(é¢„çº¦|è®¢ä½)',        # ç®€çŸ­çš„é¢„çº¦
    #     ]
    #     
    #     for pattern in simple_patterns:
    #         if re.search(pattern, content):
    #             return True
    #     
    #     # å¯¹äºå¤æ‚é—®é¢˜ï¼Œä½¿ç”¨AIç”Ÿæˆ
    #     return len(content) < 15
    
    def _update_avg_time(self, generation_time: float):
        """æ›´æ–°å¹³å‡ç”Ÿæˆæ—¶é—´"""
        if self.stats['ai_replies'] > 1:
            self.stats['avg_generation_time'] = (
                (self.stats['avg_generation_time'] * (self.stats['ai_replies'] - 1) + generation_time) 
                / self.stats['ai_replies']
            )
        else:
            self.stats['avg_generation_time'] = generation_time
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total = self.stats['total_requests']
        base_stats = {
            **self.stats,
            # 'template_rate': self.stats['template_replies'] / total if total > 0 else 0,  # å·²æ³¨é‡Š
            'ai_rate': self.stats['ai_replies'] / total if total > 0 else 0,
            'fallback_rate': self.stats['fallback_replies'] / total if total > 0 else 0
        }
        
        # åˆå¹¶AIç”Ÿæˆå™¨ç»Ÿè®¡
        ai_stats = self.ai_generator.get_stats()
        return {**base_stats, **ai_stats}
    
    async def close(self):
        """å…³é—­èµ„æº"""
        await self.ai_generator.close()


# åˆ›å»ºå…¨å±€å®ä¾‹
def create_reply_generator() -> SmartReplyGenerator:
    """åˆ›å»ºå›å¤ç”Ÿæˆå™¨å®ä¾‹"""
    return SmartReplyGenerator()


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    async def test():
        generator = create_reply_generator()
        
        test_cases = [
            "ä»·æ ¼å¤šå°‘é’±",
            "æˆ‘æƒ³é¢„çº¦ä»Šæ™šçš„ä½ç½®",
            "ä½ ä»¬åœ°å€åœ¨å“ª",
            "è¥ä¸šæ—¶é—´å‡ ç‚¹åˆ°å‡ ç‚¹",
            "æ¨èä»€ä¹ˆç‰¹è‰²èœ",
            "æœ‰ä»€ä¹ˆå¥—é¤ä¼˜æƒ å—",
            "ä½ ä»¬è¿™ä¸ªé¤å…æ€ä¹ˆæ ·ï¼Œç¯å¢ƒå¦‚ä½•"
        ]
        
        print(f"ğŸ½ï¸ æµ‹è¯• {RESTAURANT_CONFIG['name']} AIå›å¤ç³»ç»Ÿ")
        
        for i, content in enumerate(test_cases, 1):
            print(f"\n--- æµ‹è¯• {i} ---")
            print(f"é—®é¢˜: {content}")
            
            # æµ‹è¯•æ™®é€šå›å¤
            result = await generator.generate_reply(content)
            print(f"å›å¤: {result.text}")
            print(f"ç±»åˆ«: {result.category}")
            print(f"ç”Ÿæˆæ—¶é—´: {result.generation_time:.2f}s")
            
            # æµ‹è¯•æµå¼å›å¤
            print("æµå¼: ", end="")
            async for part in generator.generate_reply_stream(content):
                print(part, end="", flush=True)
            print()
        
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯: {generator.get_stats()}")
        await generator.close()
    
    asyncio.run(test())
