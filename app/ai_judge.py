#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIåˆ¤æ–­æ¨¡å— - ä¼˜åŒ–ç‰ˆæœ¬
åŸºäºå¤šå±‚è¿‡æ»¤æ¼æ–—æ¶æ„ï¼Œå®ç°æ™ºèƒ½å¼¹å¹•ä»·å€¼åˆ¤æ–­å’Œå›å¤ç”Ÿæˆ
åŒ…å«é¢„è¿‡æ»¤ã€å»é‡ã€æœ¬åœ°åˆ†ç±»ã€AIåˆ¤æ–­ã€æ‰¹å¤„ç†ç­‰åŠŸèƒ½
"""

import asyncio
import hashlib
import json
import logging
import os
import re
import time
from collections import defaultdict, deque
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from enum import Enum

import httpx
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

logger = logging.getLogger(__name__)


class ProcessAction(Enum):
    """å¤„ç†åŠ¨ä½œæšä¸¾"""
    IGNORE = "ignore"
    PROCESS = "process"
    DEFER = "defer"
    BATCH = "batch"


@dataclass
class ProcessResult:
    """å¤„ç†ç»“æœ"""
    action: ProcessAction
    confidence: float = 0.0
    reason: str = ""
    delay: float = 0.0


@dataclass
class AIJudgeResult:
    """AIåˆ¤æ–­ç»“æœ"""
    has_value: bool
    content: str
    reason: str
    category: str
    confidence: float = 0.0
    template_id: Optional[str] = None


class LRUCache:
    """ç®€å•çš„LRUç¼“å­˜å®ç°"""
    
    def __init__(self, maxsize: int = 1000):
        self.maxsize = maxsize
        self.cache = {}
        self.access_order = deque()
    
    def get(self, key: str) -> Optional[Any]:
        if key in self.cache:
            self.access_order.remove(key)
            self.access_order.append(key)
            return self.cache[key]
        return None
    
    def put(self, key: str, value: Any):
        if key in self.cache:
            self.access_order.remove(key)
        elif len(self.cache) >= self.maxsize:
            oldest = self.access_order.popleft()
            del self.cache[oldest]
        
        self.cache[key] = value
        self.access_order.append(key)
    
    def __contains__(self, key: str) -> bool:
        return key in self.cache


class TokenBucket:
    """ä»¤ç‰Œæ¡¶é™æµå™¨"""
    
    def __init__(self, capacity: int = 100, refill_rate: float = 10.0):
        self.capacity = capacity
        self.tokens = capacity
        self.refill_rate = refill_rate
        self.last_refill = time.time()
    
    def consume(self, tokens: int = 1) -> bool:
        """æ¶ˆè´¹ä»¤ç‰Œ"""
        self._refill()
        if self.tokens >= tokens:
            self.tokens -= tokens
            return True
        return False
    
    def _refill(self):
        """è¡¥å……ä»¤ç‰Œ"""
        now = time.time()
        tokens_to_add = (now - self.last_refill) * self.refill_rate
        self.tokens = min(self.capacity, self.tokens + tokens_to_add)
        self.last_refill = now


class CostTracker:
    """æˆæœ¬è¿½è¸ªå™¨"""
    
    def __init__(self, daily_budget: float = 10.0):
        self.daily_budget = daily_budget
        self.daily_cost = 0.0
        self.last_reset = datetime.now().date()
        self.cost_per_call = 0.002  # ä¼°ç®—æ¯æ¬¡APIè°ƒç”¨æˆæœ¬(ç¾å…ƒ)
    
    def record_call(self, cost: float = None):
        """è®°å½•APIè°ƒç”¨æˆæœ¬"""
        self._check_reset()
        cost = cost or self.cost_per_call
        self.daily_cost += cost
    
    def within_budget(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦åœ¨é¢„ç®—å†…"""
        self._check_reset()
        return self.daily_cost < self.daily_budget
    
    def _check_reset(self):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦é‡ç½®æ—¥æˆæœ¬"""
        today = datetime.now().date()
        if today > self.last_reset:
            self.daily_cost = 0.0
            self.last_reset = today


class KeywordFilter:
    """å…³é”®è¯è¿‡æ»¤å™¨"""
    
    def __init__(self):
        # é«˜ä»·å€¼å…³é”®è¯
        self.high_value_keywords = {
            'å’¨è¯¢': 1.0, 'é¢„çº¦': 1.0, 'æŒ‚å·': 1.0, 'çœ‹ç—…': 1.0,
            'ä»·æ ¼': 0.9, 'å¤šå°‘é’±': 0.9, 'è´¹ç”¨': 0.9, 'æ”¶è´¹': 0.9,
            'è¥ä¸šæ—¶é—´': 0.8, 'ä¸Šç­æ—¶é—´': 0.8, 'å‡ ç‚¹': 0.8,
            'åœ°å€': 0.8, 'ä½ç½®': 0.8, 'åœ¨å“ª': 0.8, 'æ€ä¹ˆèµ°': 0.8,
            'ç”µè¯': 0.7, 'è”ç³»': 0.7, 'å¾®ä¿¡': 0.7,
            'æ²»ç–—': 0.9, 'è°ƒç†': 0.9, 'ä¸­åŒ»': 0.8, 'é’ˆç¸': 0.8,
            'æ¨æ‹¿': 0.8, 'ç†ç–—': 0.8, 'æŒ‰æ‘©': 0.8,
            'æ€ä¹ˆ': 0.6, 'å¯ä»¥': 0.5, 'èƒ½ä¸èƒ½': 0.6, 'è¡Œä¸è¡Œ': 0.6
        }
        
        # è´Ÿé¢å…³é”®è¯ï¼ˆé™ä½ä»·å€¼ï¼‰
        self.negative_keywords = {
            'å“ˆå“ˆ': -0.5, 'å‘µå‘µ': -0.5, 'å˜¿å˜¿': -0.5,
            '666': -0.5, '999': -0.5, 'ç‰›æ‰¹': -0.3,
            'å‰å®³': -0.3, 'ç‰›': -0.3, 'æ£’': -0.3,
            'åˆ·å±': -1.0, 'å¹¿å‘Š': -1.0, 'åŠ ç¾¤': -1.0,
            'æ¨å¹¿': -1.0, 'ä»£ç†': -1.0, 'æ‹›è˜': -1.0
        }
        
        # åƒåœ¾å†…å®¹æ¨¡å¼
        self.spam_patterns = [
            r'[0-9]{6,}',  # é•¿æ•°å­—ä¸²
            r'[a-zA-Z]{10,}',  # é•¿å­—æ¯ä¸²
            r'(.)\1{5,}',  # é‡å¤å­—ç¬¦
            r'[ï¼!]{3,}',  # å¤šä¸ªæ„Ÿå¹å·
            r'[ã€‚.]{3,}',  # å¤šä¸ªå¥å·
            r'http[s]?://',  # ç½‘å€
            r'QQ[:ï¼š]\s*\d+',  # QQå·
            r'å¾®ä¿¡[:ï¼š]',  # å¾®ä¿¡å·
        ]
    
    def calculate_score(self, content: str) -> float:
        """è®¡ç®—å†…å®¹ä»·å€¼åˆ†æ•°"""
        if not content or len(content.strip()) < 2:
            return 0.0
        
        content = content.strip().lower()
        
        # æ£€æŸ¥åƒåœ¾å†…å®¹
        if self._is_spam(content):
            return 0.0
        
        # è®¡ç®—å…³é”®è¯å¾—åˆ†
        score = 0.0
        
        # é«˜ä»·å€¼å…³é”®è¯
        for keyword, weight in self.high_value_keywords.items():
            if keyword in content:
                score += weight
        
        # è´Ÿé¢å…³é”®è¯
        for keyword, weight in self.negative_keywords.items():
            if keyword in content:
                score += weight
        
        # é•¿åº¦è°ƒæ•´
        length_bonus = min(0.2, len(content) / 100)
        score += length_bonus
        
        return max(0.0, min(1.0, score))
    
    def _is_spam(self, content: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºåƒåœ¾å†…å®¹"""
        for pattern in self.spam_patterns:
            if re.search(pattern, content):
                return True
        return False


class LocalClassifier:
    """æœ¬åœ°è½»é‡åˆ†ç±»å™¨"""
    
    def __init__(self):
        self.keyword_filter = KeywordFilter()
        
        # é—®å¥æ¨¡å¼
        self.question_patterns = [
            r'[ï¼Ÿ?]',  # é—®å·
            r'æ€ä¹ˆ[^0-9]*',  # æ€ä¹ˆå¼€å¤´
            r'ä»€ä¹ˆ[^0-9]*',  # ä»€ä¹ˆå¼€å¤´
            r'å“ªé‡Œ[^0-9]*',  # å“ªé‡Œå¼€å¤´
            r'å‡ ç‚¹[^0-9]*',  # å‡ ç‚¹å¼€å¤´
            r'å¤šå°‘[^0-9]*',  # å¤šå°‘å¼€å¤´
            r'å¯ä»¥.*å—',  # å¯ä»¥...å—
            r'èƒ½.*å—',  # èƒ½...å—
            r'æœ‰.*å—',  # æœ‰...å—
        ]
    
    async def classify(self, content: str) -> float:
        """æœ¬åœ°åˆ†ç±»ï¼Œè¿”å›ç½®ä¿¡åº¦"""
        if not content:
            return 0.0
        
        # åŸºç¡€å…³é”®è¯å¾—åˆ†
        keyword_score = self.keyword_filter.calculate_score(content)
        
        # é—®å¥æ¨¡å¼å¾—åˆ†
        question_score = self._calculate_question_score(content)
        
        # ç»¼åˆå¾—åˆ†
        final_score = keyword_score * 0.7 + question_score * 0.3
        
        return min(1.0, final_score)
    
    def _calculate_question_score(self, content: str) -> float:
        """è®¡ç®—é—®å¥å¾—åˆ†"""
        score = 0.0
        for pattern in self.question_patterns:
            if re.search(pattern, content):
                score += 0.3
        return min(1.0, score)


class SmartBarrageProcessor:
    """æ™ºèƒ½å¼¹å¹•é¢„å¤„ç†å™¨"""
    
    def __init__(self):
        self.dedup_cache = LRUCache(maxsize=1000)
        self.keyword_filter = KeywordFilter()
        self.local_classifier = LocalClassifier()
        self.rate_limiter = TokenBucket(capacity=50, refill_rate=5.0)
        self.processed_hashes = set()
        
        # å»é‡æ—¶é—´çª—å£
        self.dedup_window = 300  # 5åˆ†é’Ÿ
    
    async def process_barrage(self, barrage: Dict) -> ProcessResult:
        """å¤„ç†å•æ¡å¼¹å¹•"""
        # 1. åŸºç¡€è¿‡æ»¤
        if not self._basic_filter(barrage):
            return ProcessResult(ProcessAction.IGNORE, reason="basic_filter")
        
        # 2. å»é‡æ£€æµ‹
        if self._is_duplicate(barrage):
            return ProcessResult(ProcessAction.IGNORE, reason="duplicate")
        
        # 3. å…³é”®è¯é¢„ç­›é€‰
        content = barrage.get('content', '')
        keyword_score = self.keyword_filter.calculate_score(content)
        if keyword_score < 0.1:
            return ProcessResult(ProcessAction.IGNORE, reason="low_keyword_score")
        
        # 4. æœ¬åœ°è½»é‡åˆ†ç±»
        local_score = await self.local_classifier.classify(content)
        if local_score < 0.3:
            return ProcessResult(ProcessAction.IGNORE, reason="low_local_score")
        
        # 5. é¢‘ç‡æ§åˆ¶
        if not self.rate_limiter.consume(1):
            return ProcessResult(ProcessAction.DEFER, reason="rate_limit", delay=2.0)
        
        # 6. å†³å®šå¤„ç†ç­–ç•¥
        if local_score > 0.8:
            return ProcessResult(ProcessAction.PROCESS, confidence=local_score)
        else:
            return ProcessResult(ProcessAction.BATCH, confidence=local_score)
    
    def _basic_filter(self, barrage: Dict) -> bool:
        """åŸºç¡€è¿‡æ»¤"""
        # æ£€æŸ¥ç±»å‹
        if barrage.get('type') not in ['chat', 'emoji_chat']:
            return False
        
        # æ£€æŸ¥å†…å®¹
        content = barrage.get('content', '').strip()
        if not content or len(content) < 2 or len(content) > 200:
            return False
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºçº¯è¡¨æƒ…
        if self._is_pure_emoji(content):
            return False
        
        return True
    
    def _is_duplicate(self, barrage: Dict) -> bool:
        """å»é‡æ£€æµ‹"""
        content = barrage.get('content', '')
        user_id = barrage.get('user_id', '')
        
        # ç”Ÿæˆå»é‡key
        content_hash = hashlib.md5(content.encode()).hexdigest()[:8]
        timestamp = barrage.get('timestamp', time.time())
        
        # æ£€æŸ¥å†…å®¹å»é‡
        content_key = f"content_{content_hash}"
        if content_key in self.dedup_cache:
            last_time = self.dedup_cache.get(content_key)
            if timestamp - last_time < self.dedup_window:
                return True
        
        # æ£€æŸ¥ç”¨æˆ·å»é‡
        user_key = f"user_{user_id}_{content_hash}"
        if user_key in self.dedup_cache:
            return True
        
        # è®°å½•
        self.dedup_cache.put(content_key, timestamp)
        self.dedup_cache.put(user_key, timestamp)
        
        return False
    
    def _is_pure_emoji(self, content: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºçº¯è¡¨æƒ…"""
        # ç®€å•çš„è¡¨æƒ…æ£€æµ‹
        emoji_pattern = r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF]'
        text_without_emoji = re.sub(emoji_pattern, '', content)
        return len(text_without_emoji.strip()) == 0


class SmartBatchProcessor:
    """æ™ºèƒ½æ‰¹å¤„ç†å™¨"""
    
    def __init__(self, ai_judge):
        self.ai_judge = ai_judge
        self.batch_size = 5
        self.max_wait_time = 10.0
        self.current_batch = []
        self.last_process_time = time.time()
        self.processing_lock = asyncio.Lock()
    
    async def add_to_batch(self, barrage: Dict) -> Optional[str]:
        """æ·»åŠ åˆ°æ‰¹å¤„ç†é˜Ÿåˆ—"""
        async with self.processing_lock:
            self.current_batch.append(barrage)
            
            # è§¦å‘æ¡ä»¶
            should_process = (
                len(self.current_batch) >= self.batch_size or
                time.time() - self.last_process_time > self.max_wait_time
            )
            
            if should_process:
                return await self._process_batch()
        
        return None
    
    async def _process_batch(self) -> Optional[str]:
        """å¤„ç†å½“å‰æ‰¹æ¬¡"""
        if not self.current_batch:
            return None
        
        try:
            # æ‰¹é‡AIåˆ¤æ–­
            batch_results = await self.ai_judge.batch_judge_barrages(self.current_batch)
            
            # æ‰¾åˆ°æœ€é«˜ä»·å€¼çš„ç»“æœ
            best_result = None
            best_score = 0.0
            
            for result in batch_results:
                if result and result.has_value and result.confidence > best_score:
                    best_result = result
                    best_score = result.confidence
            
            if best_result:
                reply = await self.ai_judge.generate_reply(best_result.content)
                self.current_batch.clear()
                self.last_process_time = time.time()
                return reply
            
        except Exception as e:
            logger.error(f"æ‰¹å¤„ç†å¤±è´¥: {e}")
        
        self.current_batch.clear()
        self.last_process_time = time.time()
        return None


class ContextAwareAIJudge:
    """ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„AIåˆ¤æ–­å™¨"""
    
    def __init__(self):
        self.api_ready = False
        self.client = None
        
        # APIé…ç½® - ä»ç¯å¢ƒå˜é‡è¯»å–
        self.api_type = os.getenv("AI_API_TYPE", "openai")
        self.api_key = os.getenv("AI_API_KEY", "")
        self.api_base = os.getenv("AI_API_BASE", "https://api.openai.com/v1")
        self.model_name = os.getenv("AI_MODEL_NAME", "gpt-4o-mini")
        
        # éªŒè¯APIé…ç½®
        if not self.api_key or self.api_key == "sk-your-api-key-here":
            logger.warning("âš ï¸ æœªé…ç½®æœ‰æ•ˆçš„AI API Keyï¼Œå°†ä½¿ç”¨ç®€åŒ–ç‰ˆåˆ¤æ–­å™¨")
        else:
            logger.info(f"ğŸ”‘ ä½¿ç”¨APIç±»å‹: {self.api_type}, æ¨¡å‹: {self.model_name}")
        
        # ç¼“å­˜å’Œä¸Šä¸‹æ–‡
        self.template_cache = LRUCache(maxsize=100)
        self.conversation_context = {}
        self.cost_tracker = CostTracker()
        
        # è¶…æ—¶é…ç½®
        self.timeout = 30.0
        self.max_retries = 3
        
        # ç³»ç»Ÿæç¤º
        self.judge_system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¼¹å¹•ä»·å€¼åˆ¤æ–­åŠ©æ‰‹ã€‚è¯·åˆ¤æ–­ä»¥ä¸‹å¼¹å¹•å†…å®¹æ˜¯å¦æœ‰å•†ä¸šä»·å€¼ã€‚

åˆ¤æ–­æ ‡å‡†ï¼š
1. æœ‰æ˜ç¡®è¯¢é—®å•†å“ã€æœåŠ¡ã€ä»·æ ¼çš„ - é«˜ä»·å€¼
2. æœ‰é¢„çº¦ã€å’¨è¯¢ã€æŒ‚å·éœ€æ±‚çš„ - é«˜ä»·å€¼  
3. è¯¢é—®è¥ä¸šæ—¶é—´ã€åœ°å€ã€è”ç³»æ–¹å¼çš„ - ä¸­ä»·å€¼
4. æœ‰æŠ•è¯‰ã€å»ºè®®çš„ - ä¸­ä»·å€¼
5. è¡¨è¾¾æ²»ç–—éœ€æ±‚çš„ - é«˜ä»·å€¼

æ— ä»·å€¼å†…å®¹ï¼š
- çº¯è¡¨æƒ…ã€ç‚¹èµã€é—²èŠ
- å¹¿å‘Šã€åˆ·å±ã€çŒæ°´
- ä¸å•†å®¶ä¸šåŠ¡æ— å…³çš„å†…å®¹

è¯·è¿”å›JSONæ ¼å¼ï¼š
{
  "has_value": true/false,
  "content": "æå–çš„å…³é”®å†…å®¹",
  "reason": "åˆ¤æ–­ç†ç”±",
  "category": "å’¨è¯¢/é¢„çº¦/è¯¢ä»·/æŠ•è¯‰/å…¶ä»–",
  "confidence": 0.0-1.0
}"""

        self.reply_system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­åŒ»ç†ç–—æœºæ„å®¢æœï¼Œéœ€è¦ç”Ÿæˆæ¸©æŸ”ã€ä¸“ä¸šã€ç®€æ´çš„å›å¤ã€‚

æœºæ„ç‰¹ç‚¹ï¼š
- ä¸“æ³¨ä¸­åŒ»ç†ç–—æœåŠ¡
- æä¾›é’ˆç¸ã€æ¨æ‹¿ã€ç†ç–—ç­‰æœåŠ¡
- æœåŠ¡æ€åº¦ä¸“ä¸šæ¸©å’Œ

å›å¤è¦æ±‚ï¼š
1. è¯­æ°”æ¸©æŸ”ã€ä¸“ä¸šã€äº²åˆ‡
2. å›å¤ç®€æ´æ˜äº†ï¼Œä¸è¶…è¿‡50å­—
3. å¯¹äºå…·ä½“ä¿¡æ¯ï¼ˆç”µè¯ã€æ—¶é—´ã€ä»·æ ¼ï¼‰ç”¨"xx"ä»£æ›¿
4. è¶…å‡ºçŸ¥è¯†èŒƒå›´æ—¶è¯´ï¼š"ç¨ç­‰ä¸€ä¸‹ï¼Œæˆ‘å’Œè€å¸ˆç¡®è®¤ä¸€ä¸‹ï¼Œç¨åå›å¤æ‚¨"
5. ä½“ç°ä¸­åŒ»ç†ç–—çš„ä¸“ä¸šæ€§

è¯·ç›´æ¥è¿”å›å›å¤æ–‡æœ¬ï¼Œä¸è¦åŒ…å«JSONæ ¼å¼ã€‚"""
        
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        asyncio.create_task(self._init_api_client())
    
    async def _init_api_client(self):
        """åˆå§‹åŒ–APIå®¢æˆ·ç«¯"""
        try:
            if self.api_type == "openai":
                await self._init_openai_client()
            else:
                logger.warning(f"ä¸æ”¯æŒçš„APIç±»å‹: {self.api_type}")
                return
            
            self.api_ready = True
            logger.info("âœ… AI APIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"âŒ AI APIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.api_ready = False
    
    async def _init_openai_client(self):
        """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
        try:
            # ä½¿ç”¨httpxä½œä¸ºåŸºç¡€å®¢æˆ·ç«¯
            self.client = httpx.AsyncClient(
                base_url=self.api_base,
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                },
                timeout=self.timeout
            )
            logger.info("OpenAI APIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def judge_barrages(self, barrages: List[Dict]) -> Optional[AIJudgeResult]:
        """åˆ¤æ–­å¼¹å¹•ä»·å€¼ï¼ˆå•ä¸ªå¤„ç†ï¼‰"""
        if not self.api_ready or not barrages:
            return None
        
        # æå–æœ‰æ•ˆå¼¹å¹•
        valid_barrages = [
            b for b in barrages 
            if b.get('type') in ['chat', 'emoji_chat'] and b.get('content', '').strip()
        ]
        
        if not valid_barrages:
            return None
        
        # æ„å»ºåˆ¤æ–­ä¸Šä¸‹æ–‡
        context = self._build_judge_context(valid_barrages)
        
        try:
            # è°ƒç”¨AIåˆ¤æ–­
            response = await self._call_openai_api(
                self.judge_system_prompt, 
                context, 
                response_format="json"
            )
            
            # è§£æç»“æœ
            result = self._parse_judge_response(response)
            if result and result.has_value:
                logger.info(f"å‘ç°æœ‰ä»·å€¼å¼¹å¹•: {result.content}")
                return result
            
        except Exception as e:
            logger.error(f"AIåˆ¤æ–­å¤±è´¥: {e}")
        
        return None
    
    async def batch_judge_barrages(self, barrages: List[Dict]) -> List[Optional[AIJudgeResult]]:
        """æ‰¹é‡åˆ¤æ–­å¼¹å¹•ä»·å€¼"""
        if not self.api_ready or not barrages:
            return []
        
        # åˆ†ç»„å¤„ç†
        results = []
        batch_size = 3  # æ¯æ¬¡å¤„ç†3æ¡å¼¹å¹•
        
        for i in range(0, len(barrages), batch_size):
            batch = barrages[i:i + batch_size]
            result = await self.judge_barrages(batch)
            results.append(result)
        
        return results
    
    async def generate_reply(self, content: str) -> Optional[str]:
        """ç”Ÿæˆå›å¤"""
        if not self.api_ready or not content:
            return None
        
        # æ£€æŸ¥æ¨¡æ¿ç¼“å­˜
        cache_key = self._generate_cache_key(content)
        if cached_reply := self.template_cache.get(cache_key):
            logger.info(f"ä½¿ç”¨ç¼“å­˜å›å¤: {cached_reply}")
            return cached_reply
        
        try:
            # æ„å»ºå›å¤ä¸Šä¸‹æ–‡
            context = f"é¡¾å®¢é—®é¢˜ï¼š{content}\n\nè¯·ç”Ÿæˆä¸“ä¸šå›å¤ï¼š"
            
            # è°ƒç”¨AIç”Ÿæˆå›å¤
            response = await self._call_openai_api(
                self.reply_system_prompt,
                context
            )
            
            # æ¸…ç†å›å¤
            reply = self._clean_reply(response)
            
            if reply:
                # ç¼“å­˜å¸¸ç”¨å›å¤
                self.template_cache.put(cache_key, reply)
                logger.info(f"ç”ŸæˆAIå›å¤: {reply}")
                return reply
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå›å¤å¤±è´¥: {e}")
        
        return None
    
    async def _call_openai_api(self, system_prompt: str, user_content: str, response_format: str = "text") -> str:
        """è°ƒç”¨OpenAI API"""
        if not self.cost_tracker.within_budget():
            raise Exception("è¶…å‡ºæ—¥æˆæœ¬é¢„ç®—")
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_content}
        ]
        
        data = {
            "model": self.model_name,
            "messages": messages,
            "max_tokens": 512,
            "temperature": 0.7,
            "top_p": 0.9
        }
        
        # å¦‚æœæ”¯æŒJSONæ¨¡å¼
        if response_format == "json" and "gpt" in self.model_name.lower():
            data["response_format"] = {"type": "json_object"}
        
        for attempt in range(self.max_retries):
            try:
                response = await self.client.post("/chat/completions", json=data)
                response.raise_for_status()
                
                result = response.json()
                content = result["choices"][0]["message"]["content"].strip()
                
                # è®°å½•æˆæœ¬
                self.cost_tracker.record_call()
                
                return content
                
            except Exception as e:
                logger.warning(f"APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{self.max_retries}): {e}")
                if attempt == self.max_retries - 1:
                    raise
                await asyncio.sleep(1 * (attempt + 1))
        
        return ""
    
    def _build_judge_context(self, barrages: List[Dict]) -> str:
        """æ„å»ºåˆ¤æ–­ä¸Šä¸‹æ–‡"""
        context_lines = []
        for barrage in barrages:
            content = barrage.get('content', '')
            user = barrage.get('user', 'unknown')
            msg_type = barrage.get('type', 'chat')
            
            context_lines.append(f"ã€{msg_type}ã€‘{user}: {content}")
        
        return "\n".join(context_lines)
    
    def _parse_judge_response(self, response: str) -> Optional[AIJudgeResult]:
        """è§£æåˆ¤æ–­å“åº”"""
        try:
            # æ¸…ç†å“åº”
            response = response.strip()
            
            # å°è¯•è§£æJSON
            if response.startswith('{') and response.endswith('}'):
                data = json.loads(response)
            else:
                # æå–JSONéƒ¨åˆ†
                json_match = re.search(r'\{[^{}]*"has_value"[^{}]*\}', response, re.DOTALL)
                if json_match:
                    data = json.loads(json_match.group())
                else:
                    return None
            
            return AIJudgeResult(
                has_value=data.get('has_value', False),
                content=data.get('content', ''),
                reason=data.get('reason', ''),
                category=data.get('category', 'other'),
                confidence=data.get('confidence', 0.0)
            )
            
        except Exception as e:
            logger.error(f"è§£æåˆ¤æ–­å“åº”å¤±è´¥: {e}")
            return None
    
    def _clean_reply(self, response: str) -> str:
        """æ¸…ç†å›å¤æ–‡æœ¬"""
        if not response:
            return ""
        
        # ç§»é™¤å¤šä½™ç©ºç™½
        reply = re.sub(r'\s+', ' ', response).strip()
        
        # ç§»é™¤å¯èƒ½çš„JSONåŒ…è£…
        if reply.startswith('"') and reply.endswith('"'):
            reply = reply[1:-1]
        
        # ç§»é™¤å›å¤å‰ç¼€
        reply = re.sub(r'^(å›å¤[:ï¼š]?\s*|ç­”[:ï¼š]?\s*)', '', reply)
        
        # é™åˆ¶é•¿åº¦
        if len(reply) > 100:
            reply = reply[:100] + "..."
        
        return reply
    
    def _generate_cache_key(self, content: str) -> str:
        """ç”Ÿæˆç¼“å­˜key"""
        # ç®€åŒ–å†…å®¹ç”¨äºç¼“å­˜
        simplified = re.sub(r'[^\w\u4e00-\u9fff]', '', content.lower())
        return hashlib.md5(simplified.encode()).hexdigest()[:8]
    
    async def close(self):
        """å…³é—­å®¢æˆ·ç«¯"""
        if self.client:
            await self.client.aclose()


class OptimizedAIJudge:
    """ä¼˜åŒ–ç‰ˆAIåˆ¤æ–­ç³»ç»Ÿ"""
    
    def __init__(self):
        self.preprocessor = SmartBarrageProcessor()
        self.ai_judge = ContextAwareAIJudge()
        self.batch_processor = SmartBatchProcessor(self.ai_judge)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_processed': 0,
            'ignored_count': 0,
            'ai_calls': 0,
            'cache_hits': 0,
            'batch_processed': 0
        }
    
    async def process_barrage_stream(self, barrage: Dict) -> Optional[str]:
        """å¤„ç†å¼¹å¹•æµ"""
        self.stats['total_processed'] += 1
        
        # é¢„å¤„ç†
        result = await self.preprocessor.process_barrage(barrage)
        
        if result.action == ProcessAction.IGNORE:
            self.stats['ignored_count'] += 1
            logger.debug(f"å¿½ç•¥å¼¹å¹•: {result.reason}")
            return None
        
        elif result.action == ProcessAction.PROCESS:
            # ç«‹å³å¤„ç†
            return await self._immediate_process(barrage)
        
        elif result.action == ProcessAction.BATCH:
            # æ‰¹å¤„ç†
            self.stats['batch_processed'] += 1
            return await self.batch_processor.add_to_batch(barrage)
        
        elif result.action == ProcessAction.DEFER:
            # å»¶è¿Ÿå¤„ç†
            await asyncio.sleep(result.delay)
            return await self._immediate_process(barrage)
        
        return None
    
    async def _immediate_process(self, barrage: Dict) -> Optional[str]:
        """ç«‹å³å¤„ç†å¼¹å¹•"""
        try:
            self.stats['ai_calls'] += 1
            
            # AIåˆ¤æ–­
            ai_result = await self.ai_judge.judge_barrages([barrage])
            
            if ai_result and ai_result.has_value:
                # ç”Ÿæˆå›å¤
                reply = await self.ai_judge.generate_reply(ai_result.content)
                return reply
            
        except Exception as e:
            logger.error(f"ç«‹å³å¤„ç†å¤±è´¥: {e}")
        
        return None
    
    async def judge_barrages(self, barrages: List[Dict]) -> Optional[Dict]:
        """å…¼å®¹åŸæ¥å£çš„åˆ¤æ–­æ–¹æ³•"""
        if not barrages:
            return None
        
        # ä½¿ç”¨æ–°çš„å¤„ç†æµç¨‹
        for barrage in barrages:
            result = await self.process_barrage_stream(barrage)
            if result:
                return {
                    'has_value': True,
                    'content': barrage.get('content', ''),
                    'reason': 'é€šè¿‡ä¼˜åŒ–æµç¨‹åˆ¤æ–­',
                    'category': 'å’¨è¯¢'
                }
        
        return None
    
    async def generate_reply(self, content: str) -> Optional[str]:
        """å…¼å®¹åŸæ¥å£çš„å›å¤ç”Ÿæˆæ–¹æ³•"""
        return await self.ai_judge.generate_reply(content)
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return self.stats.copy()
    
    async def close(self):
        """å…³é—­èµ„æº"""
        await self.ai_judge.close()


# ç®€åŒ–ç‰ˆAIåˆ¤æ–­å™¨ï¼ˆå…œåº•æ–¹æ¡ˆï¼‰
class SimpleAIJudge:
    """ç®€åŒ–ç‰ˆAIåˆ¤æ–­å™¨"""
    
    def __init__(self):
        self.keyword_filter = KeywordFilter()
        self.api_ready = True
        logger.info("ğŸ”„ ä½¿ç”¨ç®€åŒ–ç‰ˆAIåˆ¤æ–­å™¨")
    
    async def judge_barrages(self, barrages: List[Dict]) -> Optional[Dict]:
        """ç®€åŒ–ç‰ˆå¼¹å¹•åˆ¤æ–­"""
        try:
            for barrage in barrages:
                content = barrage.get('content', '')
                score = self.keyword_filter.calculate_score(content)
                
                if score > 0.5:
                    return {
                        'has_value': True,
                        'content': content,
                        'reason': 'å…³é”®è¯åŒ¹é…',
                        'category': 'å’¨è¯¢'
                    }
            
            return None
            
        except Exception as e:
            logger.error(f"ç®€åŒ–åˆ¤æ–­å¤±è´¥: {e}")
            return None
    
    async def generate_reply(self, content: str) -> Optional[str]:
        """ç®€åŒ–ç‰ˆå›å¤ç”Ÿæˆ"""
        try:
            if "é¢„çº¦" in content:
                return "æ‚¨å¥½ï¼Œé¢„çº¦è¯·è”ç³»æˆ‘ä»¬çš„å®¢æœxxï¼Œæˆ‘ä»¬ä¼šä¸ºæ‚¨å®‰æ’åˆé€‚çš„æ—¶é—´"
            elif "ä»·æ ¼" in content or "å¤šå°‘é’±" in content:
                return "æ‚¨å¥½ï¼Œå…·ä½“ä»·æ ¼è¯·å’¨è¯¢æˆ‘ä»¬çš„å®¢æœxxï¼Œæˆ‘ä»¬æœ‰å¤šç§å¥—é¤å¯é€‰æ‹©"
            elif "è¥ä¸šæ—¶é—´" in content:
                return "æ‚¨å¥½ï¼Œæˆ‘ä»¬çš„è¥ä¸šæ—¶é—´æ˜¯xxç‚¹åˆ°xxç‚¹ï¼Œå…·ä½“å¯å’¨è¯¢å®¢æœxx"
            else:
                return "æ‚¨å¥½ï¼Œæ„Ÿè°¢æ‚¨çš„å’¨è¯¢ï¼Œå…·ä½“ä¿¡æ¯è¯·è”ç³»æˆ‘ä»¬çš„å®¢æœxx"
                
        except Exception as e:
            logger.error(f"ç®€åŒ–å›å¤ç”Ÿæˆå¤±è´¥: {e}")
            return None
    
    async def close(self):
        """å…³é—­èµ„æº"""
        pass


# å·¥å‚å‡½æ•°
def create_ai_judge():
    """åˆ›å»ºAIåˆ¤æ–­å™¨å®ä¾‹"""
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„APIé…ç½®
        api_key = os.getenv("AI_API_KEY", "")
        if api_key and api_key != "sk-your-api-key-here":
            return OptimizedAIJudge()
        else:
            logger.warning("æœªé…ç½®æœ‰æ•ˆçš„AI API Keyï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆåˆ¤æ–­å™¨")
            return SimpleAIJudge()
    except Exception as e:
        logger.warning(f"åˆ›å»ºä¼˜åŒ–ç‰ˆAIåˆ¤æ–­å™¨å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆ: {e}")
        return SimpleAIJudge()


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    async def test():
        judge = create_ai_judge()
        
        test_barrages = [
            {"type": "chat", "content": "è¯·é—®ä½ ä»¬çš„ä¸­åŒ»ç†ç–—å¤šå°‘é’±", "user": "test1", "timestamp": time.time()},
            {"type": "chat", "content": "666", "user": "test2", "timestamp": time.time()},
            {"type": "chat", "content": "æˆ‘æƒ³é¢„çº¦é’ˆç¸", "user": "test3", "timestamp": time.time()},
        ]
        
        for barrage in test_barrages:
            if hasattr(judge, 'process_barrage_stream'):
                result = await judge.process_barrage_stream(barrage)
                print(f"å¼¹å¹•: {barrage['content']} -> å›å¤: {result}")
            else:
                result = await judge.judge_barrages([barrage])
                if result and result.get('has_value'):
                    reply = await judge.generate_reply(result.get('content'))
                    print(f"å¼¹å¹•: {barrage['content']} -> å›å¤: {reply}")
        
        await judge.close()
    
    asyncio.run(test())
