# Qwen3-8B å¾®è°ƒè®­ç»ƒæŒ‡å—

åŸºäº ms-swift æ¡†æ¶çš„ Qwen3-8B æ¨¡å‹å¾®è°ƒè®­ç»ƒå®Œæ•´æŒ‡å—ï¼Œä¼˜åŒ–äº† 8GB æ˜¾å­˜ç¯å¢ƒä¸‹çš„è®­ç»ƒæµç¨‹ã€‚

## ğŸ“‹ ç›®å½•

- [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
- [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡)
- [æ¨¡å‹å‡†å¤‡](#æ¨¡å‹å‡†å¤‡)
- [è®­ç»ƒæµç¨‹](#è®­ç»ƒæµç¨‹)
- [é‡è¦å‚æ•°è¯´æ˜](#é‡è¦å‚æ•°è¯´æ˜)
- [æ¨¡å‹è¯„ä¼°](#æ¨¡å‹è¯„ä¼°)
- [æ¨ç†éƒ¨ç½²](#æ¨ç†éƒ¨ç½²)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

## ğŸš€ ç¯å¢ƒå‡†å¤‡

### 1. ç³»ç»Ÿè¦æ±‚

- **GPU**: NVIDIA RTX 4060 (8GBæ˜¾å­˜) æˆ–ä»¥ä¸Š
- **å†…å­˜**: 16GB+ æ¨è
- **å­˜å‚¨**: 20GB+ å¯ç”¨ç©ºé—´
- **Python**: 3.8+
- **CUDA**: 11.8 æˆ– 12.1

### 2. å®‰è£…ä¾èµ–

```bash
# å®‰è£… ms-swift å’Œç›¸å…³ä¾èµ–
pip install ms-swift[llm]

# å®‰è£…å…¶ä»–ä¾èµ–
pip install requests tensorboard
```

### 3. éªŒè¯å®‰è£…

```bash
# æ£€æŸ¥ swift æ˜¯å¦æ­£ç¡®å®‰è£…
swift sft --help

# æ£€æŸ¥ GPU å¯ç”¨æ€§
python -c "import torch; print(torch.cuda.is_available())"
```

## ğŸ“Š æ•°æ®å‡†å¤‡

### 1. æ•°æ®æ ¼å¼

è®­ç»ƒæ•°æ®éœ€è¦è½¬æ¢ä¸ºæ ‡å‡†çš„ JSON æ ¼å¼ï¼š

```json
[
  {
    "query": "ç”¨æˆ·é—®é¢˜",
    "response": "åŠ©æ‰‹å›ç­”"
  },
  // æ›´å¤šæ•°æ®...
]
```

### 2. æ•°æ®æ–‡ä»¶

- **åŸå§‹æ•°æ®**: `./data/ååŒ»å ‚`
- **è®­ç»ƒæ•°æ®**: `./data/chatML.txt` (ChatMLæ ¼å¼)

### 3. æ•°æ®è´¨é‡è¦æ±‚

- æ¯æ¡æ•°æ®åŒ…å«å®Œæ•´çš„é—®ç­”å¯¹
- å›ç­”ç¬¦åˆå®¢æœåŠ©ç†çš„è¯­æ°”é£æ ¼
- æ•°æ®é‡å»ºè®® 100+ æ¡

## ğŸ¤– æ¨¡å‹å‡†å¤‡

### 1. ä¸‹è½½ Qwen3-8B åŸºç¡€æ¨¡å‹

```bash
# ä½¿ç”¨ Hugging Face Hub
huggingface-cli download Qwen/Qwen3-8B --local-dir ../my_models

# æˆ–ä½¿ç”¨ Git LFS
git clone https://huggingface.co/Qwen/Qwen3-8B ../my_models
```

### 2. éªŒè¯æ¨¡å‹æ–‡ä»¶

æ¨¡å‹ç›®å½•åº”åŒ…å«ä»¥ä¸‹æ–‡ä»¶ï¼š
- `config.json`
- `model-*-of-*.safetensors` (æ¨¡å‹æƒé‡åˆ†ç‰‡)
- `tokenizer.json`
- `tokenizer_config.json`

## ğŸ‹ï¸ è®­ç»ƒæµç¨‹

### 1. å¿«é€Ÿå¼€å§‹

```bash
# è¿è¡Œè®­ç»ƒè„šæœ¬
python local_train_8b.py

å¦‚æœæ˜¾å­˜ä¸å¤Ÿ 
python local_train_8b_save.py

å¦‚æœé‡åˆ°è¯„ä¼°é˜¶æ®µé”™è¯¯
python local_train_8b_safe.py
```

### 2. å®Œæ•´è®­ç»ƒå‘½ä»¤

```bash
swift sft \
  --model ../my_models \
  --model_type qwen3 \
  --dataset ./data/clean_train.json \
  --template qwen3 \
  --output_dir ./qwen3_output \
  --num_train_epochs 3 \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 16 \
  --learning_rate 3e-6 \
  --max_length 1024 \
  --logging_steps 1 \
  --save_steps 100 \
  --eval_steps 100 \
  --eval_strategy steps \
  --lora_rank 64 \
  --lora_alpha 128 \
  --lora_dropout 0.05 \
  --gradient_checkpointing true \
  --quant_method bnb \
  --quant_bits 4 \
  --bnb_4bit_compute_dtype bfloat16 \
  --bnb_4bit_quant_type nf4 \
  --bnb_4bit_use_double_quant true \
  --device_map auto
```

### 3. ç›‘æ§è®­ç»ƒè¿‡ç¨‹

```bash
# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tensorboard --logdir ./qwen3_output

# å®æ—¶æŸ¥çœ‹æ—¥å¿—
tail -f ./qwen3_output/*/logging.jsonl
```

## âš™ï¸ é‡è¦å‚æ•°è¯´æ˜

### æ ¸å¿ƒè®­ç»ƒå‚æ•°

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| `model_type` | `qwen3` | æ¨¡å‹ç±»å‹ï¼Œå¿…é¡»ä½¿ç”¨ qwen3 |
| `template` | `qwen3` | èŠå¤©æ¨¡æ¿æ ¼å¼ |
| `learning_rate` | `3e-6` | å­¦ä¹ ç‡ï¼Œ8Bæ¨¡å‹é€‚ç”¨ |
| `num_train_epochs` | `3` | è®­ç»ƒè½®æ•° |
| `max_length` | `1024` | æœ€å¤§åºåˆ—é•¿åº¦ |

### æ˜¾å­˜ä¼˜åŒ–å‚æ•°

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| `per_device_train_batch_size` | `1` | å•è®¾å¤‡æ‰¹æ¬¡å¤§å° |
| `gradient_accumulation_steps` | `16` | æ¢¯åº¦ç´¯ç§¯æ­¥æ•° |
| `quant_bits` | `4` | 4bité‡åŒ–ï¼ŒèŠ‚çœæ˜¾å­˜ |
| `gradient_checkpointing` | `true` | æ¢¯åº¦æ£€æŸ¥ç‚¹ |
| `device_map` | `auto` | è‡ªåŠ¨è®¾å¤‡æ˜ å°„ |

### LoRA å‚æ•°

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| `lora_rank` | `64` | LoRA ç§©ï¼Œå½±å“å‚æ•°é‡ |
| `lora_alpha` | `128` | LoRA ç¼©æ”¾å‚æ•° |
| `lora_dropout` | `0.05` | LoRA Dropoutç‡ |

### é‡åŒ–å‚æ•°

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| `quant_method` | `bnb` | ä½¿ç”¨ BitsAndBytes é‡åŒ– |
| `bnb_4bit_compute_dtype` | `bfloat16` | è®¡ç®—æ•°æ®ç±»å‹ |
| `bnb_4bit_quant_type` | `nf4` | é‡åŒ–ç±»å‹ |
| `bnb_4bit_use_double_quant` | `true` | åŒé‡é‡åŒ– |

## ğŸ“ˆ æ¨¡å‹è¯„ä¼°

### 1. è‡ªåŠ¨åŒ–æµ‹è¯•

```bash
# è¿è¡Œè‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬
python model_test.py

# æˆ–æŒ‡å®šé…ç½®æ–‡ä»¶
python model_test.py --config models_config.json
```

### 2. æ‰‹åŠ¨æ¨ç†æµ‹è¯•

```bash
# å¯åŠ¨æ¨ç†æœåŠ¡
swift deploy \
  --model ./qwen3_output/checkpoint-XXX \
  --model_type qwen3 \
  --template qwen3 \
  --port 8000

# æµ‹è¯•API
curl -X POST "http://localhost:8000/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen3",
    "messages": [
      {"role": "system", "content": "ä½ æ˜¯ååŒ»å ‚çš„å®¢æœåŠ©ç†"},
      {"role": "user", "content": "ä½ ä»¬è¥ä¸šåˆ°å‡ ç‚¹ï¼Ÿ"}
    ],
    "max_tokens": 256
  }'
```

### 3. è¯„ä¼°æŒ‡æ ‡

- **ä¸»è§‚è¯„åˆ†**: 1-5åˆ†åˆ¶äººå·¥è¯„ä¼°
- **å“åº”é€Ÿåº¦**: æ¨ç†æ—¶é—´ç»Ÿè®¡
- **ç­”æ¡ˆè´¨é‡**: ä¸“ä¸šæ€§ã€å‡†ç¡®æ€§ã€è¯­æ°”
- **ä¸€è‡´æ€§**: å¤šæ¬¡æŸ¥è¯¢ç»“æœçš„ç¨³å®šæ€§

## ğŸš€ æ¨ç†éƒ¨ç½²

### 1. æœ¬åœ°éƒ¨ç½²

```bash
# éƒ¨ç½²å¾®è°ƒåçš„æ¨¡å‹
swift deploy \
  --model ./qwen3_output/checkpoint-best \
  --model_type qwen3 \
  --template qwen3 \
  --port 8000 \
  --quant_method bnb \
  --quant_bits 4
```

### 2. ç”Ÿäº§ç¯å¢ƒ

```bash
# ä½¿ç”¨ vllm è¿›è¡Œé«˜æ€§èƒ½æ¨ç†
vllm serve ./qwen3_output/checkpoint-best \
  --model qwen3 \
  --port 8000 \
  --gpu-memory-utilization 0.8
```

### 3. API ä½¿ç”¨ç¤ºä¾‹

```python
import requests

url = "http://localhost:8000/v1/chat/completions"
payload = {
    "model": "qwen3",
    "messages": [
        {"role": "system", "content": "ä½ æ˜¯ååŒ»å ‚çš„å®¢æœåŠ©ç†"},
        {"role": "user", "content": "æˆ‘æƒ³é¢„çº¦æŒ‰æ‘©"}
    ],
    "temperature": 0.3,
    "max_tokens": 256
}

response = requests.post(url, json=payload)
print(response.json()["choices"][0]["message"]["content"])
```

## ğŸ“ æ–‡ä»¶ç»“æ„

```
fine-tune/
â”œâ”€â”€ local_train_8b.py          # æ ‡å‡†è®­ç»ƒè„šæœ¬
â”œâ”€â”€ local_train_8b_save.py     # æ˜¾å­˜ä¼˜åŒ–å®‰å…¨è®­ç»ƒç‰ˆæœ¬
â”œâ”€â”€ local_train_8b_safe.py     # ç‰ˆæœ¬ï¼ˆè§£å†³è¯„ä¼°é”™è¯¯ï¼‰
â”œâ”€â”€ model_test.py              # è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬
â”œâ”€â”€ models_config.json         # æ¨¡å‹é…ç½®æ–‡ä»¶
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ clean_train.json       # è®­ç»ƒæ•°æ®
â”‚   â””â”€â”€ chatML.txt            # åŸå§‹æ•°æ®
â”œâ”€â”€ qwen3_output/             # è®­ç»ƒè¾“å‡º
â”‚   â”œâ”€â”€ v0-*/                 # è®­ç»ƒç‰ˆæœ¬ç›®å½•
â”‚   â”œâ”€â”€ v1-*/
â”‚   â””â”€â”€ ...
â””â”€â”€ README.md                 # æœ¬æ–‡æ¡£
```

## â“ å¸¸è§é—®é¢˜

### Q1: CUDA å†…å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**:
- é™ä½ `per_device_train_batch_size` åˆ° 1
- å¢åŠ  `gradient_accumulation_steps`
- ä½¿ç”¨ 4bit é‡åŒ– (`quant_bits: 4`)
- å¯ç”¨ `gradient_checkpointing`

### Q2: è®­ç»ƒé€Ÿåº¦æ…¢

**è§£å†³æ–¹æ¡ˆ**:
- å‡å°‘ `max_length`
- ä½¿ç”¨æ›´å°çš„ `lora_rank`
- å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (`bf16: true`)

### Q3: æ¨¡å‹å›ç­”ä¸ç¬¦åˆæœŸæœ›

**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥è®­ç»ƒæ•°æ®è´¨é‡
- è°ƒæ•´ `learning_rate`
- å¢åŠ è®­ç»ƒæ•°æ®é‡
- ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯

### Q4: æ¨ç†æœåŠ¡å¯åŠ¨å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®
- ç¡®è®¤ç«¯å£æœªè¢«å ç”¨
- éªŒè¯æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§

### Q5: è¯„ä¼°é˜¶æ®µIndexErroré”™è¯¯

**é”™è¯¯ç°è±¡**:
```
IndexError: list assignment index out of range
encoded['labels'][0] = -100
```

**æ ¹æœ¬åŸå› **:
- è¯„ä¼°é˜¶æ®µæŸäº›æ•°æ®æ ·æœ¬ç¼–ç å¤±è´¥ï¼Œå¯¼è‡´labelsåˆ—è¡¨ä¸ºç©º
- chatMLæ ¼å¼æ•°æ®ä¸qwen3æ¨¡æ¿å¯èƒ½å­˜åœ¨å…¼å®¹æ€§é—®é¢˜
- è®­ç»ƒå’Œè¯„ä¼°çš„æ•°æ®é¢„å¤„ç†ä¸ä¸€è‡´

**è§£å†³æ–¹æ¡ˆ**:
1. **ä½¿ç”¨å®‰å…¨è®­ç»ƒè„šæœ¬**:
   ```bash
   python local_train_8b_safe.py
   ```

2. **ç¦ç”¨è¯„ä¼°**:
   ```bash
   --eval_strategy no
   ```

3. **åˆ‡æ¢æ•°æ®æ ¼å¼**:
   ```bash
   # ä»chatML.txtåˆ‡æ¢åˆ°clean_train.json
   --dataset ./data/clean_train.json
   ```

4. **å‡å°‘è¯„ä¼°é¢‘ç‡**:
   ```bash
   --eval_steps 1000  # å¤§å¹…å¢åŠ è¯„ä¼°é—´éš”
   --save_steps 100   # ä¿æŒä¿å­˜é¢‘ç‡
   ```

5. **æ·»åŠ å®‰å…¨å‚æ•°**:
   ```bash
   --prediction_loss_only true      # åªè®¡ç®—æŸå¤±
   --dataloader_num_workers 0       # é¿å…å¤šè¿›ç¨‹é—®é¢˜
   --ignore_data_skip true          # å¿½ç•¥æ•°æ®è·³è¿‡
   ```

## ğŸ“Š æ€§èƒ½åŸºå‡†

### è®­ç»ƒæ€§èƒ½ (RTX 4060 8GB)

| é…ç½® | æ‰¹æ¬¡å¤§å° | æ˜¾å­˜ä½¿ç”¨ | è®­ç»ƒæ—¶é—´/epoch |
|------|----------|----------|----------------|
| 4bité‡åŒ– | 1 Ã— 16 | ~7.5GB | ~30åˆ†é’Ÿ |
| 8bité‡åŒ– | 1 Ã— 8  | ~6.8GB | ~25åˆ†é’Ÿ |

### æ¨ç†æ€§èƒ½

| é…ç½® | å»¶è¿Ÿ | ååé‡ | æ˜¾å­˜å ç”¨ |
|------|------|--------|----------|
| 4bité‡åŒ– | ~1.2s | ~15 tokens/s | ~4GB |
| FP16 | ~0.8s | ~25 tokens/s | ~16GB |

## ğŸ”— ç›¸å…³é“¾æ¥

- [ms-swift å®˜æ–¹æ–‡æ¡£](https://github.com/modelscope/swift)
- [Qwen3 æ¨¡å‹ä»‹ç»](https://github.com/QwenLM/Qwen)
- [LoRA è®ºæ–‡](https://arxiv.org/abs/2106.09685)
- [BitsAndBytes é‡åŒ–](https://github.com/TimDettmers/bitsandbytes)

## ğŸ“ æ›´æ–°æ—¥å¿—

- **v1.0.0**: åˆå§‹ç‰ˆæœ¬ï¼Œæ”¯æŒåŸºç¡€è®­ç»ƒæµç¨‹
- **v1.1.0**: æ–°å¢ 4bit é‡åŒ–æ”¯æŒ
- **v1.2.0**: æ·»åŠ è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬
- **v1.3.0**: ä¼˜åŒ–æ˜¾å­˜ä½¿ç”¨ï¼Œæ”¯æŒ 8GB æ˜¾å¡
- **v1.4.0**: è§£å†³è¯„ä¼°é˜¶æ®µIndexErroré”™è¯¯ï¼Œæ–°å¢å®‰å…¨è®­ç»ƒæ¨¡å¼

---

ğŸ¯ **å¿«é€Ÿå¼€å§‹**: `python local_train_8b.py`

ğŸ“§ **é—®é¢˜åé¦ˆ**: å¦‚é‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶æˆ–æäº¤ Issueã€‚ 