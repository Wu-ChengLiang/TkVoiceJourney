#!/usr/bin/env python3
"""
4.2é˜¶æ®µï¼šåˆ›å»ºæ¸…æ´çš„è®­ç»ƒæ•°æ®é›†
ä½¿ç”¨æ–¹æ¡ˆC - æœ€ç®€åŒ–æ ¼å¼ï¼Œé¿å…æ‰€æœ‰å¯¹è¯æ ¼å¼æ±¡æŸ“
"""

import json
from pathlib import Path
import re

def clean_and_validate_data():
    """æ¸…æ´å’ŒéªŒè¯è®­ç»ƒæ•°æ®"""
    
    print("ğŸ§¹ å¼€å§‹åˆ›å»ºæ¸…æ´è®­ç»ƒæ•°æ®é›† - æ–¹æ¡ˆC")
    print("ğŸ¯ ç›®æ ‡ï¼šç§»é™¤æ‰€æœ‰æ ¼å¼æ±¡æŸ“ï¼Œä½¿ç”¨æœ€ç®€åŒ–query-responseæ ¼å¼")
    print("=" * 60)
    
    # è¯»å–åŸå§‹æ•°æ®
    original_data_path = Path("../data/output/train_data.json")
    
    if not original_data_path.exists():
        print(f"âŒ åŸå§‹æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {original_data_path}")
        return None
        
    with open(original_data_path, 'r', encoding='utf-8') as f:
        original_data = json.load(f)
    
    print(f"ğŸ“Š åŸå§‹æ•°æ®: {len(original_data)}æ¡")
    
    # å®šä¹‰éœ€è¦æ¸…ç†çš„æ±¡æŸ“å…³é”®è¯
    pollution_keywords = [
        'è¯·æ ¹æ®ç¾å›¢å¼€åº—å®çš„ç›¸å…³çŸ¥è¯†å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚',
        'è¯·æ ¹æ®',
        'æ ¹æ®ä»¥ä¸‹ä¿¡æ¯',
        'è¯·å›ç­”',
        'æ ¹æ®ä¸Šä¸‹æ–‡'
    ]
    
    # åˆ›å»ºæ¸…æ´æ•°æ®é›†
    clean_data = []
    skipped_count = 0
    
    for i, item in enumerate(original_data):
        try:
            # æå–çº¯å‡€çš„é—®é¢˜å’Œå›ç­”
            question = item['input'].strip()
            answer = item['output'].strip()
            
            # æ•°æ®è´¨é‡æ£€æŸ¥
            if not question or not answer:
                print(f"âš ï¸  è·³è¿‡ç©ºæ•°æ®: ç´¢å¼• {i}")
                skipped_count += 1
                continue
                
            if len(question) < 3 or len(answer) < 10:
                print(f"âš ï¸  è·³è¿‡è¿‡çŸ­æ•°æ®: ç´¢å¼• {i}")
                skipped_count += 1
                continue
            
            # æ¸…ç†é—®é¢˜å’Œå›ç­”ä¸­çš„æ ¼å¼æ±¡æŸ“
            for keyword in pollution_keywords:
                question = question.replace(keyword, '').strip()
                answer = answer.replace(keyword, '').strip()
            
            # æ¸…ç†å¤šä½™ç©ºç™½å’Œæ¢è¡Œ
            question = re.sub(r'\s+', ' ', question).strip()
            answer = re.sub(r'\s+', ' ', answer).strip()
            
            # å†æ¬¡æ£€æŸ¥æ¸…ç†åçš„å†…å®¹
            if not question or not answer:
                print(f"âš ï¸  æ¸…ç†åä¸ºç©ºï¼Œè·³è¿‡: ç´¢å¼• {i}")
                skipped_count += 1
                continue
            
            # ç¡®ä¿é—®é¢˜ä»¥åˆé€‚çš„æ ‡ç‚¹ç»“å°¾
            if not question.endswith(('ï¼Ÿ', '?', 'ã€‚', '.', 'ï¼š', ':')):
                if any(word in question for word in ['ä»€ä¹ˆ', 'å¦‚ä½•', 'æ€ä¹ˆ', 'å“ªäº›', 'èƒ½å¦', 'æ˜¯å¦']):
                    if not question.endswith('ï¼Ÿ'):
                        question += 'ï¼Ÿ'
            
            # åˆ›å»ºæ–¹æ¡ˆCæ ¼å¼ï¼šæœ€ç®€åŒ–query-response
            clean_item = {
                "query": question,
                "response": answer
            }
            
            clean_data.append(clean_item)
            
        except Exception as e:
            print(f"âŒ å¤„ç†æ•°æ® {i} æ—¶å‡ºé”™: {e}")
            skipped_count += 1
            continue
    
    print(f"âœ… æ•°æ®æ¸…æ´å®Œæˆ:")
    print(f"  ğŸ“¥ åŸå§‹æ•°æ®: {len(original_data)}æ¡")
    print(f"  ğŸ“¤ æ¸…æ´æ•°æ®: {len(clean_data)}æ¡")
    print(f"  ğŸ—‘ï¸  è·³è¿‡æ•°æ®: {skipped_count}æ¡")
    print()
    
    # æ˜¾ç¤ºæ¸…æ´å‰åå¯¹æ¯”
    if clean_data:
        print("ğŸ” æ¸…æ´å‰åå¯¹æ¯”ç¤ºä¾‹:")
        print("--- åŸå§‹æ ¼å¼ ---")
        orig_sample = original_data[0]
        print(f"instruction: '{orig_sample['instruction']}'")
        print(f"input: '{orig_sample['input']}'")
        print(f"output: '{orig_sample['output']}'")
        print()
        print("--- æ¸…æ´åæ ¼å¼ (æ–¹æ¡ˆC) ---")
        clean_sample = clean_data[0]
        print(f"query: '{clean_sample['query']}'")
        print(f"response: '{clean_sample['response']}'")
        print()
    
    return clean_data

def save_clean_dataset(clean_data, format_name="clean"):
    """ä¿å­˜æ¸…æ´æ•°æ®é›†"""
    
    if not clean_data:
        print("âŒ æ²¡æœ‰æ¸…æ´æ•°æ®å¯ä¿å­˜")
        return None
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("./data")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜æ¸…æ´æ•°æ®é›†
    clean_path = output_dir / f"{format_name}_train.json"
    
    with open(clean_path, 'w', encoding='utf-8') as f:
        json.dump(clean_data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ æ¸…æ´æ•°æ®é›†å·²ä¿å­˜: {clean_path.absolute()}")
    print(f"ğŸ“¦ æ–‡ä»¶å¤§å°: {clean_path.stat().st_size / 1024:.2f} KB")
    
    return clean_path

def validate_clean_dataset(clean_path):
    """éªŒè¯æ¸…æ´æ•°æ®é›†è´¨é‡"""
    
    print("\nğŸ” éªŒè¯æ¸…æ´æ•°æ®é›†è´¨é‡...")
    
    with open(clean_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    issues = []
    
    # æ£€æŸ¥æ ¼å¼ä¸€è‡´æ€§
    for i, item in enumerate(data):
        if not isinstance(item, dict):
            issues.append(f"ç´¢å¼• {i}: ä¸æ˜¯å­—å…¸æ ¼å¼")
            continue
            
        if 'query' not in item or 'response' not in item:
            issues.append(f"ç´¢å¼• {i}: ç¼ºå°‘å¿…è¦å­—æ®µ")
            continue
            
        if len(item) != 2:
            issues.append(f"ç´¢å¼• {i}: åŒ…å«é¢å¤–å­—æ®µ: {list(item.keys())}")
            
        # æ£€æŸ¥å†…å®¹è´¨é‡
        query = item['query']
        response = item['response']
        
        if not query or not response:
            issues.append(f"ç´¢å¼• {i}: åŒ…å«ç©ºå†…å®¹")
            
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ ¼å¼æ±¡æŸ“ç—•è¿¹
        pollution_keywords = [
            'è¯·æ ¹æ®', 'ç¾å›¢å¼€åº—å®çš„ç›¸å…³çŸ¥è¯†', 'Human:', '<|im_start|>', 
            '<|im_end|>', 'æ ¹æ®ä»¥ä¸‹ä¿¡æ¯', 'è¯·å›ç­”', 'æ ¹æ®ä¸Šä¸‹æ–‡'
        ]
        
        for keyword in pollution_keywords:
            if keyword in query or keyword in response:
                issues.append(f"ç´¢å¼• {i}: å¯èƒ½çš„æ ¼å¼æ±¡æŸ“ '{keyword}'")
    
    # ç»Ÿè®¡ä¿¡æ¯
    avg_query_len = sum(len(item['query']) for item in data) / len(data)
    avg_response_len = sum(len(item['response']) for item in data) / len(data)
    
    print(f"ğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
    print(f"  æ€»æ•°é‡: {len(data)}æ¡")
    print(f"  å¹³å‡é—®é¢˜é•¿åº¦: {avg_query_len:.1f}å­—ç¬¦")
    print(f"  å¹³å‡å›ç­”é•¿åº¦: {avg_response_len:.1f}å­—ç¬¦")
    print(f"  å‘ç°é—®é¢˜: {len(issues)}ä¸ª")
    
    if issues:
        print("\nâš ï¸  å‘ç°çš„é—®é¢˜:")
        for issue in issues[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"  - {issue}")
        if len(issues) > 10:
            print(f"  ... è¿˜æœ‰ {len(issues) - 10} ä¸ªé—®é¢˜")
    else:
        print("âœ… æ•°æ®é›†è´¨é‡æ£€æŸ¥é€šè¿‡ï¼")
    
    return len(issues) == 0

def create_sample_preview(clean_path):
    """åˆ›å»ºæ ·æœ¬é¢„è§ˆ"""
    
    print("\nğŸ“ æ•°æ®æ ·æœ¬é¢„è§ˆ:")
    
    with open(clean_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # æ˜¾ç¤ºå‰3ä¸ªæ ·æœ¬
    for i, item in enumerate(data[:3]):
        print(f"\n--- æ ·æœ¬ {i+1} ---")
        print(f"Query: {item['query']}")
        print(f"Response: {item['response']}")
    
    print(f"\n... å…± {len(data)} æ¡æ•°æ®")

def main():
    """ä¸»å‡½æ•°"""
    
    print("ğŸš€ æ‰§è¡Œé˜¶æ®µ4.2ï¼šåˆ›å»ºæ¸…æ´çš„è®­ç»ƒæ•°æ®é›†")
    print("ğŸ’¡ é‡‡ç”¨æ–¹æ¡ˆCï¼šæœ€ç®€åŒ–query-responseæ ¼å¼")
    print("ğŸ¯ ç›®æ ‡ï¼šå®Œå…¨æ¶ˆé™¤æ ¼å¼æ±¡æŸ“ï¼Œæå‡æ¨¡å‹è´¨é‡")
    print("=" * 60)
    
    # æ­¥éª¤1ï¼šæ¸…æ´æ•°æ®
    clean_data = clean_and_validate_data()
    if not clean_data:
        print("âŒ æ•°æ®æ¸…æ´å¤±è´¥")
        return 1
    
    # æ­¥éª¤2ï¼šä¿å­˜æ¸…æ´æ•°æ®é›†
    clean_path = save_clean_dataset(clean_data, "clean")
    if not clean_path:
        print("âŒ ä¿å­˜æ¸…æ´æ•°æ®é›†å¤±è´¥")
        return 1
    
    # æ­¥éª¤3ï¼šéªŒè¯æ•°æ®è´¨é‡
    is_valid = validate_clean_dataset(clean_path)
    
    # æ­¥éª¤4ï¼šåˆ›å»ºé¢„è§ˆ
    create_sample_preview(clean_path)
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    if is_valid:
        print("ğŸ‰ é˜¶æ®µ4.2å®Œæˆï¼æ¸…æ´æ•°æ®é›†åˆ›å»ºæˆåŠŸ")
        print(f"ğŸ“ æ¸…æ´æ•°æ®è·¯å¾„: {clean_path.absolute()}")
        print("\nâœ… ä¸»è¦æ”¹è¿›:")
        print("  - ç§»é™¤äº†æ‰€æœ‰instructionå‰ç¼€æ±¡æŸ“")
        print("  - ä½¿ç”¨æœ€ç®€åŒ–query-responseæ ¼å¼")
        print("  - é¿å…äº†conversationså¯¹è¯æ ‡è®°")
        print("  - æ¸…ç†äº†å¤šä½™çš„ç©ºç™½å’Œæ ¼å¼")
        print("  - ä¿®å¤äº†responseä¸­çš„æ ¼å¼æ±¡æŸ“")
        print("\nğŸ¯ ä¸‹ä¸€æ­¥ï¼šæ‰§è¡Œ4.3ä¼˜åŒ–æç¤ºè¯æ¨¡æ¿è®¾è®¡")
    else:
        print("âš ï¸  é˜¶æ®µ4.2å®Œæˆï¼Œä½†å‘ç°æ•°æ®è´¨é‡é—®é¢˜")
        print("å»ºè®®æ£€æŸ¥å¹¶ä¿®å¤é—®é¢˜åå†ç»§ç»­")
    
    return 0 if is_valid else 1

if __name__ == "__main__":
    exit(code=main()) 