#!/usr/bin/env python3
"""
Qwen3-8Bæ¨¡å‹8bité‡åŒ–è®­ç»ƒä¼˜åŒ–ç‰ˆ - æ”¯æŒæ—©åœå’Œæ˜¾å­˜ä¼˜åŒ–
"""

import subprocess
import sys
import json
import os
from pathlib import Path
import glob

def check_local_model():
    """æ£€æŸ¥Qwen3-8Bæ¨¡å‹æ–‡ä»¶"""
    model_path = Path("../my_models")
    print(f"ğŸ” æ£€æŸ¥Qwen3-8Bæ¨¡å‹: {model_path.absolute()}")
    
    if not (model_path / "config.json").exists():
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {model_path / 'config.json'}")
        return False
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯Qwen3-8Bæ¨¡å‹
    try:
        with open(model_path / "config.json", 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        model_type = config.get('model_type', '')
        hidden_size = config.get('hidden_size', 0)
        num_layers = config.get('num_hidden_layers', 0)
        
        # Qwen3-8Bç‰¹å¾: hidden_size=4096, num_hidden_layers=36
        if model_type == 'qwen3' or (hidden_size == 4096 and num_layers == 36):
            print(f"âœ… æ£€æµ‹åˆ°Qwen3-8Bæ¨¡å‹ (hidden_size: {hidden_size}, layers: {num_layers})")
        elif 'qwen' in model_type:
            print(f"âš ï¸  æ£€æµ‹åˆ°å…¶ä»–Qwenæ¨¡å‹: {model_type} (hidden_size: {hidden_size})")
        else:
            print(f"âš ï¸  æœªçŸ¥æ¨¡å‹ç±»å‹: {model_type}")
    except Exception as e:
        print(f"âš ï¸  è¯»å–é…ç½®å¤±è´¥: {e}")
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    safetensors_files = list(model_path.glob("model-*-of-*.safetensors"))
    single_model_file = model_path / "model.safetensors"
    
    if not safetensors_files and not single_model_file.exists():
        print(f"âŒ æ¨¡å‹æƒé‡æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    if safetensors_files:
        print(f"âœ… å‘ç° {len(safetensors_files)} ä¸ªæ¨¡å‹åˆ†ç‰‡æ–‡ä»¶")
    elif single_model_file.exists():
        print(f"âœ… å‘ç°å•ä¸€æ¨¡å‹æ–‡ä»¶: model.safetensors")
    
    print(f"âœ… Qwen3-8Bæ¨¡å‹æ£€æŸ¥å®Œæˆ")
    return True

def start_advanced_training():
    """å¯åŠ¨Qwen3-8Bä¼˜åŒ–è®­ç»ƒæµç¨‹"""
    print("ğŸš€ å¯åŠ¨Qwen3-8B 8bitä¼˜åŒ–è®­ç»ƒ")
    print("ğŸ¯ é…ç½®: 4060ç¬”è®°æœ¬ 8GBæ˜¾å­˜")
    print("ğŸ§  æ”¯æŒ: Thinkingæ¨¡å¼è®­ç»ƒ")
    print("=" * 50)
    
    if not check_local_model():
        return 1

    # Qwen3-8Bè®­ç»ƒå‘½ä»¤ä¼˜åŒ–
    cmd = [
        'swift', 'sft',
        '--model', '../my_models',
        '--model_type', 'qwen3',  # ä½¿ç”¨qwen3è€Œä¸æ˜¯qwen3-8b
        '--dataset', './data/chatML.txt',
        #æ•°æ®é›†åŠ è½½çš„ä½ç½®
        '--output_dir', './qwen3_output',
        '--num_train_epochs', '4',
        '--per_device_train_batch_size', '1',      # 8Bæ¨¡å‹éœ€è¦å°batch
        '--gradient_accumulation_steps', '32',     # å¢å¤§æ¢¯åº¦ç´¯ç§¯
        '--learning_rate', '3e-6',                 # Qwen3-8Bé€‚ç”¨å­¦ä¹ ç‡
        # '--max_length', '1024',                    # å¢åŠ åºåˆ—é•¿åº¦
        '--max_length', '512', 
        '--logging_steps', '1',
        '--save_steps', '100',
        # '--eval_steps', '100',                   # ç¦ç”¨è¯„ä¼°é¿å…é”™è¯¯
        # '--eval_strategy', 'steps',              # ç¦ç”¨è¯„ä¼°ç­–ç•¥
        '--eval_strategy', 'no',                   # å®Œå…¨ç¦ç”¨è¯„ä¼°
        '--lora_rank', '16',                       # é€‚ä¸­çš„LoRA rank
        '--lora_alpha', '128',
        '--lora_dropout', '0.05',
        '--gradient_checkpointing', 'true',        # æ˜¾å­˜ä¼˜åŒ–
        '--warmup_ratio', '0.1',
        '--weight_decay', '0.01',
        '--lr_scheduler_type', 'cosine_with_restarts',
        '--save_total_limit', '3',
        '--dataloader_num_workers', '1',
        '--bf16', 'true',                          # ä½¿ç”¨bf16
        '--fp16', 'false',
        '--report_to', 'tensorboard',
        '--remove_unused_columns', 'false',        # ä¿æŒæ•°æ®å®Œæ•´æ€§
        '--predict_with_generate', 'true',         # ç”Ÿæˆå¼è¯„ä¼°
        '--generation_max_length', '512',          # ç”Ÿæˆé•¿åº¦é™åˆ¶
        # æ–°å¢é‡å¤å“åº”æŠ‘åˆ¶å‚æ•°
        # '--generation_config', '{"repetition_penalty": 1.2, "no_repeat_ngram_size": 3}',
    ]

    # Qwen3ç‰¹æœ‰é…ç½®
    print("ğŸ“Š Qwen3-8Bä¸“å±é…ç½®:")
    print("  ğŸ§  æ¨¡å‹ç±»å‹: Qwen3-8B (8.2Bå‚æ•°)")
    print("  ğŸ­ æ¨¡æ¿: qwen3 (æ”¯æŒthinkingæ¨¡å¼)")
    print("  âš¡ åºåˆ—é•¿åº¦: 1024 tokens")
    print("  ğŸ’¾ æ˜¾å­˜ä¼˜åŒ–: 4bité‡åŒ– + æ¢¯åº¦æ£€æŸ¥ç‚¹")
    print("  ğŸ”§ LoRA: rank=64, alpha=128")
    print("  ğŸ“ˆ å­¦ä¹ ç‡: 3e-6 (8Bæ¨¡å‹ä¼˜åŒ–)")
    print("  ğŸ›‘ æ—©åœ: 5æ­¥æ— æ”¹å–„è‡ªåŠ¨åœæ­¢")
    print()
    
    print("â³ å¼€å§‹Qwen3-8Bè®­ç»ƒ...")
    print("=" * 50)
    
    # ç¯å¢ƒå˜é‡ä¼˜åŒ– (8Bæ¨¡å‹ä¸“ç”¨)
    env = os.environ.copy()
    env["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True,max_split_size_mb:32"  # æ›´ç»†ç²’åº¦å†…å­˜ç®¡ç†
    env["NCCL_P2P_DISABLE"] = "1"
    env["OMP_NUM_THREADS"] = "2"  # å‡å°‘CPUçº¿ç¨‹æ•°
    env["CUDA_VISIBLE_DEVICES"] = "0"  # ç¡®ä¿åªä½¿ç”¨å•å¡
    
    # æ·»åŠ æ›´æ¿€è¿›çš„æ˜¾å­˜ä¼˜åŒ–
    cmd.extend([
        '--device_map', 'auto',  # è‡ªåŠ¨è®¾å¤‡æ˜ å°„
        '--quant_method', 'bnb',  # ä½¿ç”¨BitsAndBytesé‡åŒ–
        '--quant_bits', '4',      # ä½¿ç”¨4bité‡åŒ–ä»£æ›¿8bit
        '--bnb_4bit_compute_dtype', 'bfloat16',  # è®¡ç®—dtype
        '--bnb_4bit_quant_type', 'nf4',  # ä½¿ç”¨nf4é‡åŒ–ç±»å‹
        '--bnb_4bit_use_double_quant', 'true',  # ä½¿ç”¨åŒé‡é‡åŒ–
        '--model_kwargs', '{"llm_int8_enable_fp32_cpu_offload": true}',  # å¯ç”¨CPU offload
    ])
    
    try:
        process = subprocess.Popen(
            cmd,
            env=env,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1,
            universal_newlines=True
        )
        
        # å¢å¼ºæ—¥å¿—è§£æ (Qwen3ç‰¹åŒ–)
        while True:
            output = process.stdout.readline()
            if not output and process.poll() is not None:
                break
            if output:
                line = output.strip()
                
                # å…³é”®ä¿¡æ¯é«˜äº®
                if 'loss' in line and 'eval' not in line:
                    print(f"ğŸ“‰ è®­ç»ƒæŸå¤±: {line}")
                elif 'eval_loss' in line:
                    print(f"ğŸ” éªŒè¯æŸå¤±: {line}")
                elif 'early stopping' in line:
                    print(f"ğŸ›‘ æ—©åœè§¦å‘: {line}")
                elif 'thinking' in line.lower():
                    print(f"ğŸ§  Thinkingæ¨¡å¼: {line}")
                elif 'CUDA' in line and 'memory' in line:
                    print(f"ğŸ’¾ æ˜¾å­˜ä¿¡æ¯: {line}")
                elif 'error' in line.lower() or 'failed' in line.lower():
                    print(f"âŒ é”™è¯¯: {line}")
                else:
                    print(line)
        
        return_code = process.poll()
        
        if return_code == 0:
            print("\nğŸ‰ Qwen3-8Bè®­ç»ƒå®Œæˆ!")
            print("ğŸ“ è¾“å‡ºç›®å½•: ./qwen3_output")
            print("ğŸ“Š æŸ¥çœ‹è®­ç»ƒæ—¥å¿—: tensorboard --logdir ./qwen3_output")
        
        return return_code
    
    except KeyboardInterrupt:
        print("\nâš ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        process.terminate()
        return 1
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {e}")
        return 1

def check_swift_installation():
    """æ£€æŸ¥ms-swiftæ˜¯å¦æ­£ç¡®å®‰è£…"""
    try:
        # ä¸ä½¿ç”¨--helpï¼Œç›´æ¥æ£€æŸ¥swiftå‘½ä»¤æ˜¯å¦å­˜åœ¨å¹¶å¯ä»¥è¿è¡Œ
        # ä½¿ç”¨ä¸€ä¸ªç®€å•çš„å‘½ä»¤æ¥æ£€æŸ¥swiftæ˜¯å¦å¯ç”¨
        result = subprocess.run(['swift', 'sft'], capture_output=True, text=True, timeout=5)
        # swift sft æ²¡æœ‰å‚æ•°ä¼šè¿”å›é0çŠ¶æ€ç ä½†ä¸æ„å‘³ç€å®‰è£…æœ‰é—®é¢˜
        # æˆ‘ä»¬æ£€æŸ¥stderrä¸­æ˜¯å¦æœ‰å…³é”®çš„å®‰è£…ç›¸å…³é”™è¯¯ä¿¡æ¯
        if 'not found' in result.stderr.lower() or 'no module' in result.stderr.lower():
            print("âŒ ms-swift æœªæ­£ç¡®å®‰è£…")
            print(f"é”™è¯¯ä¿¡æ¯: {result.stderr}")
            return False
        else:
            print("âœ… ms-swift å·²æ­£ç¡®å®‰è£…")
            return True
    except FileNotFoundError:
        print("âŒ æœªæ‰¾åˆ°swiftå‘½ä»¤ï¼Œè¯·å®‰è£…ms-swift")
        print("ğŸ’¡ å®‰è£…å‘½ä»¤: pip install ms-swift[llm]")
        return False
    except subprocess.TimeoutExpired:
        # å¦‚æœå‘½ä»¤æ²¡æœ‰è¶…æ—¶é”™è¯¯ï¼Œè¯´æ˜swiftå‘½ä»¤å­˜åœ¨ä¸”å¯ä»¥è¿è¡Œ
        print("âœ… ms-swift å·²æ­£ç¡®å®‰è£…")
        return True
    except Exception as e:
        print(f"âŒ æ£€æŸ¥ms-swiftæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return False

if __name__ == "__main__":
    print("ğŸ¯ Qwen3-8B 8bité‡åŒ–è®­ç»ƒå¯åŠ¨å™¨")
    print("=" * 40)
    
    # æ£€æŸ¥ä¾èµ–
    if not check_swift_installation():
        print("\nâŒ è¯·å…ˆå®‰è£…ms-swift:")
        print("pip install ms-swift[llm]")
        sys.exit(1)
    
    # å¯åŠ¨è®­ç»ƒ
    sys.exit(start_advanced_training())