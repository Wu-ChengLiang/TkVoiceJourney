#!/usr/bin/env python3
"""
TkVoiceJourney æ¨¡å‹æ€§èƒ½æµ‹è¯•
æµ‹è¯•æ˜¾å­˜ä½¿ç”¨ã€æ¨ç†é€Ÿåº¦å’Œè¾“å‡ºè´¨é‡
"""

import sys
import time
import torch
import gc
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root / "deploy"))

from config import get_config
from chat import OptimizedChatModel

class ModelPerformanceTester:
    """æ¨¡å‹æ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.config = get_config()
        self.test_questions = [
            "åœ¨å—ï¼Ÿæƒ³é¢„çº¦ä¸‹åˆ3ç‚¹",
            "æ–¹ä¾¿åœè½¦å—ï¼Ÿ",
            "æœ‰å¥³è€å¸ˆå—ï¼Ÿ",
            "ä½ ä»¬è¥ä¸šåˆ°å‡ ç‚¹ï¼Ÿ",
            "å¯ä»¥åŠ å¾®ä¿¡å—ï¼Ÿ",
            "ä»·æ ¼æ€ä¹ˆæ ·ï¼Ÿ",
            "åœ°å€åœ¨å“ªé‡Œï¼Ÿ",
            "éœ€è¦æå‰é¢„çº¦å—ï¼Ÿ"
        ]
        
    def test_memory_usage(self, model: OptimizedChatModel) -> dict:
        """æµ‹è¯•æ˜¾å­˜ä½¿ç”¨æƒ…å†µ"""
        print("\nğŸ” æ˜¾å­˜ä½¿ç”¨æµ‹è¯•")
        print("-" * 30)
        
        results = {}
        
        if not torch.cuda.is_available():
            print("âŒ æœªæ£€æµ‹åˆ°CUDA")
            return results
            
        # æ¸…ç†æ˜¾å­˜
        model.clear_memory()
        
        # è·å–åŸºå‡†æ˜¾å­˜
        baseline_memory = torch.cuda.memory_allocated() / (1024**3)
        
        # æµ‹è¯•åŠ è½½åçš„æ˜¾å­˜
        if model.model is not None:
            loaded_memory = torch.cuda.memory_allocated() / (1024**3)
            model_memory = loaded_memory - baseline_memory
        else:
            model_memory = 0
            
        total_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        
        results = {
            "baseline_memory_gb": baseline_memory,
            "model_memory_gb": model_memory,
            "total_memory_gb": total_memory,
            "memory_utilization": (loaded_memory / total_memory) * 100
        }
        
        print(f"ğŸ“Š åŸºå‡†æ˜¾å­˜: {baseline_memory:.2f}GB")
        print(f"ğŸ“Š æ¨¡å‹æ˜¾å­˜: {model_memory:.2f}GB")
        print(f"ğŸ“Š æ€»æ˜¾å­˜: {total_memory:.1f}GB")
        print(f"ğŸ“Š åˆ©ç”¨ç‡: {results['memory_utilization']:.1f}%")
        
        # åˆ¤æ–­æ˜¾å­˜ä½¿ç”¨æ˜¯å¦åˆç†
        if results['memory_utilization'] < 90:
            print("âœ… æ˜¾å­˜ä½¿ç”¨æ­£å¸¸")
        else:
            print("âš ï¸  æ˜¾å­˜ä½¿ç”¨æ¥è¿‘æé™")
            
        return results
    
    def test_inference_speed(self, model: OptimizedChatModel) -> dict:
        """æµ‹è¯•æ¨ç†é€Ÿåº¦"""
        print("\nâš¡ æ¨ç†é€Ÿåº¦æµ‹è¯•")
        print("-" * 30)
        
        if model.model is None:
            print("âŒ æ¨¡å‹æœªåŠ è½½")
            return {}
            
        times = []
        
        for i, question in enumerate(self.test_questions[:5], 1):
            print(f"ğŸ§ª æµ‹è¯• {i}/5: {question}")
            
            start_time = time.time()
            response = model.generate_response(question)
            end_time = time.time()
            
            response_time = end_time - start_time
            times.append(response_time)
            
            print(f"â±ï¸  è€—æ—¶: {response_time:.2f}s")
            print(f"ğŸ’¬ å›å¤: {response[:50]}{'...' if len(response) > 50 else ''}")
            print()
        
        results = {
            "average_time": sum(times) / len(times),
            "min_time": min(times),
            "max_time": max(times),
            "times": times
        }
        
        print(f"ğŸ“ˆ å¹³å‡å“åº”æ—¶é—´: {results['average_time']:.2f}s")
        print(f"ğŸ“ˆ æœ€å¿«å“åº”: {results['min_time']:.2f}s")
        print(f"ğŸ“ˆ æœ€æ…¢å“åº”: {results['max_time']:.2f}s")
        
        return results
    
    def test_output_quality(self, model: OptimizedChatModel) -> dict:
        """æµ‹è¯•è¾“å‡ºè´¨é‡ï¼ˆæ€ç»´é“¾è¿‡æ»¤ç­‰ï¼‰"""
        print("\nğŸ¯ è¾“å‡ºè´¨é‡æµ‹è¯•")
        print("-" * 30)
        
        if model.model is None:
            print("âŒ æ¨¡å‹æœªåŠ è½½")
            return {}
        
        quality_checks = {
            "has_thinking_chains": 0,
            "has_user_repetition": 0,
            "empty_responses": 0,
            "appropriate_responses": 0
        }
        
        for i, question in enumerate(self.test_questions, 1):
            print(f"ğŸ§ª è´¨é‡æ£€æŸ¥ {i}/{len(self.test_questions)}: {question}")
            
            response = model.generate_response(question)
            
            # æ£€æŸ¥æ€ç»´é“¾æ³„éœ²
            thinking_patterns = ['<think>', '</think>', '<æ€è€ƒ>', '</æ€è€ƒ>', '[æ€è€ƒ]', '[æƒ³æ³•]']
            if any(pattern in response for pattern in thinking_patterns):
                quality_checks["has_thinking_chains"] += 1
                print("âŒ å‘ç°æ€ç»´é“¾æ³„éœ²")
            
            # æ£€æŸ¥ç”¨æˆ·è¾“å…¥é‡å¤
            if 'user:' in response.lower():
                quality_checks["has_user_repetition"] += 1
                print("âŒ å‘ç°ç”¨æˆ·è¾“å…¥é‡å¤")
            
            # æ£€æŸ¥ç©ºå›å¤
            if len(response.strip()) < 2:
                quality_checks["empty_responses"] += 1
                print("âŒ å›å¤è¿‡çŸ­æˆ–ä¸ºç©º")
            
            # æ£€æŸ¥å›å¤é€‚å½“æ€§
            if (len(response) >= 2 and 
                not any(pattern in response for pattern in thinking_patterns) and
                'user:' not in response.lower()):
                quality_checks["appropriate_responses"] += 1
                print("âœ… å›å¤è´¨é‡è‰¯å¥½")
            
            print(f"ğŸ’¬ å›å¤: {response}")
            print()
        
        total_tests = len(self.test_questions)
        quality_score = (quality_checks["appropriate_responses"] / total_tests) * 100
        
        print(f"ğŸ“Š è´¨é‡è¯„åˆ†: {quality_score:.1f}%")
        print(f"ğŸ“Š é€‚å½“å›å¤: {quality_checks['appropriate_responses']}/{total_tests}")
        print(f"ğŸ“Š æ€ç»´é“¾æ³„éœ²: {quality_checks['has_thinking_chains']}")
        print(f"ğŸ“Š ç”¨æˆ·è¾“å…¥é‡å¤: {quality_checks['has_user_repetition']}")
        print(f"ğŸ“Š ç©ºå›å¤: {quality_checks['empty_responses']}")
        
        return {
            **quality_checks,
            "total_tests": total_tests,
            "quality_score": quality_score
        }
    
    def run_full_test(self, model_name: str = None, quantization: str = None):
        """è¿è¡Œå®Œæ•´æµ‹è¯•"""
        print("ğŸ§ª TkVoiceJourney æ¨¡å‹æ€§èƒ½æµ‹è¯•")
        print("=" * 50)
        
        # åˆ›å»ºæ¨¡å‹å®ä¾‹
        chat_model = OptimizedChatModel(model_name, quantization)
        
        # æµ‹è¯•æ¨¡å‹åŠ è½½
        print("ğŸš€ åŠ è½½æ¨¡å‹...")
        if not chat_model.setup_model():
            print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæµ‹è¯•ç»ˆæ­¢")
            return
        
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # è¿è¡Œå„é¡¹æµ‹è¯•
        memory_results = self.test_memory_usage(chat_model)
        speed_results = self.test_inference_speed(chat_model)
        quality_results = self.test_output_quality(chat_model)
        
        # æ±‡æ€»æµ‹è¯•ç»“æœ
        print("\nğŸ“‹ æµ‹è¯•ç»“æœæ±‡æ€»")
        print("=" * 50)
        
        print(f"ğŸ“¦ æµ‹è¯•æ¨¡å‹: {chat_model.model_name}")
        print(f"âš¡ é‡åŒ–é…ç½®: {chat_model.quantization}")
        
        if memory_results:
            print(f"ğŸ’¾ æ˜¾å­˜ä½¿ç”¨: {memory_results['model_memory_gb']:.2f}GB ({memory_results['memory_utilization']:.1f}%)")
        
        if speed_results:
            print(f"â±ï¸  å¹³å‡å“åº”: {speed_results['average_time']:.2f}s")
        
        if quality_results:
            print(f"ğŸ¯ è´¨é‡è¯„åˆ†: {quality_results['quality_score']:.1f}%")
        
        # æ¸…ç†èµ„æº
        chat_model.clear_memory()
        print("\nğŸ§¹ æµ‹è¯•å®Œæˆï¼Œèµ„æºå·²æ¸…ç†")
        
        return {
            "memory": memory_results,
            "speed": speed_results,
            "quality": quality_results
        }

def main():
    """ä¸»å‡½æ•°"""
    tester = ModelPerformanceTester()
    
    # å¯ä»¥æŒ‡å®šè¦æµ‹è¯•çš„é…ç½®
    model_name = None  # ä½¿ç”¨é»˜è®¤æ¨¡å‹
    quantization = None  # ä½¿ç”¨é»˜è®¤é‡åŒ–
    
    # è¿è¡Œæµ‹è¯•
    results = tester.run_full_test(model_name, quantization)
    
    return results

if __name__ == "__main__":
    main() 