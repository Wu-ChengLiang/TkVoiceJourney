#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenAIå…¼å®¹APIä½¿ç”¨ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•åƒä½¿ç”¨OpenAI SDKä¸€æ ·è°ƒç”¨Fish Audio TTSå’ŒLLM API
"""

import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.core.openai_compatible import OpenAI, OpenAICompatibleClient


async def basic_chat_example():
    """åŸºç¡€èŠå¤©ç¤ºä¾‹"""
    print("=" * 50)
    print("ğŸ“ åŸºç¡€èŠå¤©ç¤ºä¾‹")
    print("=" * 50)
    
    # åˆ›å»ºå®¢æˆ·ç«¯ï¼ˆå’ŒOpenAI SDKç”¨æ³•ä¸€æ ·ï¼‰
    client = OpenAI()
    
    # éæµå¼èŠå¤©
    print("\nğŸ’¬ éæµå¼èŠå¤©:")
    response = await client.chat.create(
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„ä¸­æ–‡åŠ©æ‰‹"},
            {"role": "user", "content": "è¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}
        ],
        model="gpt-3.5-turbo",  # å®é™…ä½¿ç”¨é…ç½®ä¸­çš„æ¨¡å‹
        temperature=0.7,
        stream=False
    )
    
    print(f"åŠ©æ‰‹: {response['choices'][0]['message']['content']}")


async def stream_chat_example():
    """æµå¼èŠå¤©ç¤ºä¾‹"""
    print("\n=" * 50)
    print("ğŸ”„ æµå¼èŠå¤©ç¤ºä¾‹")
    print("=" * 50)
    
    client = OpenAI()
    
    print("\nğŸ”„ æµå¼èŠå¤©:")
    print("åŠ©æ‰‹: ", end="", flush=True)
    
    stream = await client.chat.create(
        messages=[
            {"role": "user", "content": "ç”¨100å­—å·¦å³ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹"}
        ],
        stream=True
    )
    
    async for chunk in stream:
        if chunk['choices'][0]['delta'].get('content'):
            print(chunk['choices'][0]['delta']['content'], end="", flush=True)
    
    print()  # æ¢è¡Œ


async def tts_example():
    """æ–‡æœ¬è½¬è¯­éŸ³ç¤ºä¾‹"""
    print("\n=" * 50)
    print("ğŸµ æ–‡æœ¬è½¬è¯­éŸ³ç¤ºä¾‹")
    print("=" * 50)
    
    client = OpenAI()
    
    # æµ‹è¯•æ–‡æœ¬
    test_texts = [
        "ä½ å¥½ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªæµ‹è¯•éŸ³é¢‘ã€‚",
        "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜æˆ‘ä»¬çš„ä¸–ç•Œï¼Œè®©ç”Ÿæ´»å˜å¾—æ›´åŠ ä¾¿æ·ã€‚",
        "Fish Audio æä¾›äº†é«˜è´¨é‡çš„è¯­éŸ³åˆæˆæœåŠ¡ã€‚"
    ]
    
    for i, text in enumerate(test_texts, 1):
        print(f"\nğŸµ ç”ŸæˆéŸ³é¢‘ {i}: {text}")
        
        # ç”ŸæˆéŸ³é¢‘ï¼ˆå’ŒOpenAI TTS APIç”¨æ³•ä¸€æ ·ï¼‰
        audio_data = await client.audio.speech.create(
            model="tts-1",  # å®é™…ä½¿ç”¨Fish Audio
            input=text,
            voice="alloy",  # å®é™…ä½¿ç”¨é…ç½®ä¸­çš„éŸ³è‰²
            response_format="mp3"
        )
        
        if audio_data:
            filename = f"example_audio_{i}.mp3"
            with open(filename, "wb") as f:
                f.write(audio_data)
            print(f"âœ… éŸ³é¢‘å·²ä¿å­˜: {filename} ({len(audio_data)} å­—èŠ‚)")
        else:
            print("âŒ éŸ³é¢‘ç”Ÿæˆå¤±è´¥")


async def integrated_chat_tts_example():
    """é›†æˆèŠå¤©+TTSç¤ºä¾‹"""
    print("\n=" * 50)
    print("ğŸ­ é›†æˆèŠå¤©+TTSç¤ºä¾‹")
    print("=" * 50)
    
    # ä½¿ç”¨åº•å±‚å®¢æˆ·ç«¯çš„é›†æˆåŠŸèƒ½
    client = OpenAICompatibleClient()
    
    questions = [
        "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹Pythonç¼–ç¨‹è¯­è¨€",
        "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
        "äººå·¥æ™ºèƒ½æœ‰å“ªäº›åº”ç”¨åœºæ™¯ï¼Ÿ"
    ]
    
    for i, question in enumerate(questions, 1):
        print(f"\nğŸ¤” é—®é¢˜ {i}: {question}")
        print("åŠ©æ‰‹: ", end="", flush=True)
        
        # æµå¼å¯¹è¯+TTSé›†æˆ
        stream = client.stream_chat_with_tts(
            user_input=question,
            system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯åŠ©æ‰‹ï¼Œç”¨ç®€æ´æ˜äº†çš„è¯­è¨€å›ç­”é—®é¢˜ã€‚",
            enable_tts=True
        )
        
        audio_data = None
        async for chunk in stream:
            if chunk['type'] == 'text':
                print(chunk['content'], end="", flush=True)
            elif chunk['type'] == 'audio':
                import base64
                audio_data = base64.b64decode(chunk['content'])
                print(f"\nğŸµ ç”ŸæˆTTSéŸ³é¢‘: {len(audio_data)} å­—èŠ‚")
        
        # ä¿å­˜éŸ³é¢‘
        if audio_data:
            filename = f"integrated_audio_{i}.mp3"
            with open(filename, "wb") as f:
                f.write(audio_data)
            print(f"âœ… éŸ³é¢‘å·²ä¿å­˜: {filename}")
        
        print()  # åˆ†éš”çº¿


async def health_check_example():
    """å¥åº·æ£€æŸ¥ç¤ºä¾‹"""
    print("\n=" * 50)
    print("ğŸ¥ å¥åº·æ£€æŸ¥ç¤ºä¾‹")
    print("=" * 50)
    
    client = OpenAICompatibleClient()
    
    print("ğŸ” æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€...")
    health = await client.health_check()
    
    print(f"ğŸ“Š å¥åº·çŠ¶æ€: {health['status']}")
    print(f"ğŸ“‹ ç»„ä»¶çŠ¶æ€:")
    for component, status in health['components'].items():
        emoji = "âœ…" if status == "ok" else "âŒ"
        print(f"  {emoji} {component.upper()}: {status}")
    
    # æµ‹è¯•è¿æ¥
    connections = client.test_connection()
    print(f"\nğŸ”— è¿æ¥æµ‹è¯•:")
    for service, status in connections.items():
        emoji = "âœ…" if status else "âŒ"
        print(f"  {emoji} {service.upper()}: {'è¿æ¥æ­£å¸¸' if status else 'è¿æ¥å¤±è´¥'}")


async def switch_llm_mode_example():
    """æ¼”ç¤ºLLMæ¨¡å¼åˆ‡æ¢"""
    print("\n=" * 50)
    print("ğŸ”„ LLMæ¨¡å¼åˆ‡æ¢æ¼”ç¤º")
    print("=" * 50)
    
    # è¿™é‡Œæ¼”ç¤ºå¦‚ä½•é€šè¿‡ç¯å¢ƒå˜é‡åˆ‡æ¢æ¨¡å¼
    # å®é™…ä½¿ç”¨æ—¶ï¼Œä¿®æ”¹.envæ–‡ä»¶ä¸­çš„LLM_MODEå³å¯
    
    from src.config import LLM_MODE, get_current_llm_config
    
    print(f"ğŸ“ å½“å‰LLMæ¨¡å¼: {LLM_MODE}")
    config = get_current_llm_config()
    print(f"ğŸ“Š å½“å‰é…ç½®: {config}")
    
    print("\nğŸ’¡ å¦‚ä½•åˆ‡æ¢LLMæ¨¡å¼:")
    print("1. ç¼–è¾‘æ ¹ç›®å½•çš„ .env æ–‡ä»¶")
    print("2. ä¿®æ”¹ LLM_MODE=openai æˆ– LLM_MODE=vllm")
    print("3. é…ç½®ç›¸åº”çš„API Keyå’ŒBase URL")
    print("4. é‡å¯åº”ç”¨")
    
    print("\nğŸ”§ OpenAIæ¨¡å¼é…ç½®:")
    print("   LLM_MODE=openai")
    print("   OPENAI_API_KEY=your_openai_key")
    print("   OPENAI_BASE_URL=https://api.openai.com/v1")
    print("   OPENAI_MODEL=gpt-4o-mini")
    
    print("\nğŸ”§ VLLMæ¨¡å¼é…ç½®:")
    print("   LLM_MODE=vllm")
    print("   VLLM_BASE_URL=https://your-vllm-endpoint.com/v1")
    print("   VLLM_API_KEY=EMPTY")
    print("   VLLM_MODEL=Qwen2.5-7B-Instruct")


async def environment_setup_guide():
    """ç¯å¢ƒé…ç½®æŒ‡å—"""
    print("\n=" * 50)
    print("âš™ï¸ ç¯å¢ƒé…ç½®æŒ‡å—")
    print("=" * 50)
    
    print("""
ğŸ“‹ é…ç½®æ­¥éª¤:

1. ç¼–è¾‘æ ¹ç›®å½•çš„ .env æ–‡ä»¶
2. é…ç½®å¿…è¦çš„APIå¯†é’¥:
   - OPENAI_API_KEY (å¦‚æœä½¿ç”¨OpenAI)
   - FISH_API_KEY (Fish Audio TTS)
   - FISH_REFERENCE_ID (Fish Audio éŸ³è‰²ID)

3. å¯é€‰é…ç½®:
   - VLLM_BASE_URL (å¦‚æœä½¿ç”¨VLLM)
   - TTS_FORMAT, TTS_BACKEND ç­‰

ğŸ“ ç¤ºä¾‹ .env é…ç½®:

# LLMé…ç½®
LLM_MODE=openai
OPENAI_API_KEY=sk-your-openai-key
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4o-mini

# Fish Audio TTSé…ç½®
FISH_API_KEY=your-fish-audio-key
FISH_REFERENCE_ID=your-reference-id
TTS_FORMAT=mp3
TTS_BACKEND=speech-1.6

ğŸ”§ è·å–Fish Audioé…ç½®:
1. è®¿é—® https://fish.audio
2. æ³¨å†Œè´¦æˆ·å¹¶è·å–API Key
3. åœ¨Playgroundä¸­é€‰æ‹©æˆ–åˆ›å»ºéŸ³è‰²ï¼Œè·å–Reference ID

ğŸš€ ä½¿ç”¨æ–¹æ³•:
   # åƒä½¿ç”¨OpenAI SDKä¸€æ ·ä½¿ç”¨
   from src.core.openai_compatible import OpenAI
   
   client = OpenAI()
   response = await client.chat.create(...)
   audio = await client.audio.speech.create(...)
""")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ‰ TkVoiceJourney OpenAIå…¼å®¹API ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 70)
    
    try:
        # å¥åº·æ£€æŸ¥
        await health_check_example()
        
        # æ£€æŸ¥æœåŠ¡æ˜¯å¦å¥åº·
        client = OpenAICompatibleClient()
        health = await client.health_check()
        
        if health['status'] != 'healthy':
            print("\nâŒ æœåŠ¡ä¸å¥åº·ï¼Œè¯·æ£€æŸ¥é…ç½®")
            await environment_setup_guide()
            return
        
        # è¿è¡Œç¤ºä¾‹
        await basic_chat_example()
        await stream_chat_example()
        await tts_example()
        await integrated_chat_tts_example()
        await switch_llm_mode_example()
        
        print("\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆ!")
        print("\nğŸ“š æŸ¥çœ‹ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶:")
        import glob
        audio_files = glob.glob("*.mp3")
        for file in audio_files:
            print(f"  ğŸµ {file}")
        
    except Exception as e:
        print(f"\nâŒ ç¤ºä¾‹è¿è¡Œå¤±è´¥: {e}")
        print("\nğŸ”§ è¯·æ£€æŸ¥é…ç½®:")
        await environment_setup_guide()
        
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main()) 